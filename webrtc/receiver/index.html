<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Baby Monitor – Receiver</title>
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"/>
  <style>
    :root { color-scheme: dark; }
    html, body {
      margin: 0; height: 100%;
      background: #000; color: #fff;
      font-family: -apple-system, system-ui, Segoe UI, Roboto, sans-serif;
      overflow: hidden;
    }
    /* Prefer dynamic viewport units (iOS 16+), fall back to classic */
    video#remote {
      position: fixed; inset: 0;
      width: 100vw; height: 100vh;
      width: 100dvw; height: 100dvh;
      object-fit: contain; background: #000; z-index: 1;
    }
    canvas#poseCanvas {
      position: fixed; /* left/top/width/height set via JS to match video’s painted box */
      z-index: 2; pointer-events: none; background: transparent; display: none;
    }

    .btn {
      padding: 12px 14px; border-radius: 12px; border: 1px solid rgba(255,255,255,0.6);
      background: transparent; color: #fff; font-size: 16px; font-weight: 600;
      cursor: pointer; box-shadow: none;
      text-shadow: 0 1px 2px rgba(0,0,0,0.6);
    }
    .btn:active { transform: scale(0.99); }

    #controls {
      position: fixed; left: 50%; bottom: 16px; transform: translateX(-50%);
      display: flex; align-items: center; gap: 12px; z-index: 6;
    }
    #enableAudioBtn, #disableAudioBtn { display: none; }

    .overlay {
      position: fixed; inset: 0; display: flex;
      align-items: center; justify-content: center;
      pointer-events: none; z-index: 5;
    }
    .status {
      background: rgba(255,255,255,0.05);
      border: 1px solid rgba(255,255,255,0.1);
      color: #ddd; font-size: 14px; padding: 10px 14px; border-radius: 12px;
      text-align: center; white-space: pre-line; max-width: 90vw;
    }
    .overlay.hidden { display: none; }
  </style>
</head>
<body>
  <div id="controls">
    <button id="enableAudioBtn" class="btn" type="button">Enable audio</button>
    <button id="disableAudioBtn" class="btn" type="button">Disable audio</button>
    <button id="fsBtn" class="btn" type="button">Fullscreen</button>
  </div>

  <video id="remote" autoplay playsinline></video>
  <canvas id="poseCanvas"></canvas>

  <div id="overlay" class="overlay">
    <div id="status" class="status">Idle</div>
  </div>

  <script type="module">
    import { DrawingUtils, PoseLandmarker } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    const WS_ENDPOINT = "wss://signaling-server-f5gu.onrender.com/ws";
    const room = new URLSearchParams(location.search).get("room") || "Baby";
    const WS_KEEPALIVE_MS = 25000;
    const WS_RECONNECT_MIN_MS = 1000;
    const WS_RECONNECT_MAX_MS = 10000;
    const RESTART_ON_ICE_TIMEOUT_MS = 5000;
    const STATUS_HIDE_AFTER_CONNECTED_MS = 10000;

    const remoteVideo = document.getElementById('remote');
    const poseCanvas  = document.getElementById('poseCanvas');
    const poseCtx     = poseCanvas.getContext('2d', { alpha: true });

    const fsBtn = document.getElementById('fsBtn');
    const enableAudioBtn = document.getElementById('enableAudioBtn');
    const disableAudioBtn = document.getElementById('disableAudioBtn');
    const overlay = document.getElementById('overlay');
    const statusEl = document.getElementById('status');

    let ws = null, wsKeepalive = null, wsRetryMs = WS_RECONNECT_MIN_MS;
    let pc = null;
    let remoteDescriptionSet = false;
    let lastAnswerSdp = null;
    const candidateQueue = [];
    let offerResendTimer = null;
    let iceDisconnectedSince = null;
    let hideStatusTimer = null;

    // Pose DC + draw state
    let poseDC = null;
    let poseEnabled = false;
    let poseWhere   = 'sender';

    // ---------- Status ----------
    function showStatus(msg) {
      statusEl.textContent = msg;
      overlay.classList.remove('hidden');
      console.log('[STATUS]', msg);
      if (msg === 'Connected') {
        if (hideStatusTimer) clearTimeout(hideStatusTimer);
        hideStatusTimer = setTimeout(() => overlay.classList.add('hidden'), STATUS_HIDE_AFTER_CONNECTED_MS);
      } else {
        if (hideStatusTimer) { clearTimeout(hideStatusTimer); hideStatusTimer = null; }
        overlay.classList.remove('hidden');
      }
    }

    // ---------- Audio UI ----------
    function updateAudioButtons() {
      if (remoteVideo.muted) {
        enableAudioBtn.style.display = 'block';
        disableAudioBtn.style.display = 'none';
      } else {
        enableAudioBtn.style.display = 'none';
        disableAudioBtn.style.display = 'block';
      }
    }
    enableAudioBtn.style.display = 'block';
    async function tryStartMuted() {
      try {
        remoteVideo.muted = true;
        remoteVideo.volume = 1.0;
        await remoteVideo.play();
      } catch (e) { console.warn('autoplay (muted) blocked:', e); }
      updateAudioButtons();
    }
    enableAudioBtn.addEventListener('click', async (e) => {
      e?.stopPropagation?.(); e?.preventDefault?.();
      try { remoteVideo.muted = false; remoteVideo.volume = 1.0; await remoteVideo.play(); }
      catch (err) { console.warn('unmute play blocked:', err); }
      updateAudioButtons();
    });
    disableAudioBtn.addEventListener('click', (e) => {
      e?.stopPropagation?.(); e?.preventDefault?.();
      remoteVideo.muted = true;
      updateAudioButtons();
    });

    // ---------- Fullscreen ----------
    fsBtn.addEventListener('click', async (e) => {
      e.stopPropagation();
      try {
        if (!document.fullscreenElement) {
          await (remoteVideo.requestFullscreen?.call(remoteVideo) || document.documentElement.requestFullscreen());
          fsBtn.textContent = 'Exit fullscreen';
        } else {
          await document.exitFullscreen();
          fsBtn.textContent = 'Fullscreen';
        }
      } catch (err) { console.warn('fullscreen error', err); }
      alignCanvasToVideo(); // snap after FS toggle
    });
    document.addEventListener('fullscreenchange', alignCanvasToVideo);
    document.addEventListener('click', () => {
      if (document.fullscreenElement) document.exitFullscreen().catch(()=>{});
    });

    remoteVideo.addEventListener('loadedmetadata', () => {
      console.log('[MEDIA] remote meta', remoteVideo.videoWidth, 'x', remoteVideo.videoHeight);
      beginViewportSettle();
    });
    remoteVideo.addEventListener('playing', () => {
      console.log('[MEDIA] remote playing (muted=', remoteVideo.muted, ')');
      updateAudioButtons();
      beginViewportSettle();
    });

    // ---------- Canvas alignment (robust to iOS rotation/toolbars) ----------
    function containRect(containerW, containerH, contentW, contentH) {
      const scale = Math.min(containerW / (contentW||1), containerH / (contentH||1));
      const w = Math.round(contentW * scale);
      const h = Math.round(contentH * scale);
      const x = Math.floor((containerW - w) / 2);
      const y = Math.floor((containerH - h) / 2);
      return { left:x, top:y, width:w, height:h };
    }

    function alignCanvasToVideo() {
      // Where is the <video> element *on screen*?
      const box = remoteVideo.getBoundingClientRect(); // in CSS px, viewport coords
      const containerW = Math.round(box.width);
      const containerH = Math.round(box.height);
      const vidW = remoteVideo.videoWidth  || 1;
      const vidH = remoteVideo.videoHeight || 1;

      // What is the painted image rect *inside* that element (object-fit: contain)?
      const fit = containRect(containerW, containerH, vidW, vidH);

      // Place canvas exactly over that painted rect (position: fixed uses viewport coords)
      const leftCSS = Math.round(box.left + fit.left);
      const topCSS  = Math.round(box.top  + fit.top);

      poseCanvas.style.left   = leftCSS + 'px';
      poseCanvas.style.top    = topCSS  + 'px';
      poseCanvas.style.width  = fit.width  + 'px';
      poseCanvas.style.height = fit.height + 'px';

      const dpr = window.devicePixelRatio || 1;
      const needW = Math.max(1, Math.round(fit.width  * dpr));
      const needH = Math.max(1, Math.round(fit.height * dpr));
      if (poseCanvas.width !== needW || poseCanvas.height !== needH) {
        poseCanvas.width  = needW;
        poseCanvas.height = needH;
      }
      poseCtx.setTransform(1,0,0,1,0,0);
    }

    // Re-align through the “settle” period after rotation / toolbar animation
    let settleRAF = 0, settleUntil = 0;
    function beginViewportSettle(durationMs = 1000) {
      settleUntil = performance.now() + durationMs;
      if (settleRAF) return;
      const tick = () => {
        alignCanvasToVideo();
        if (performance.now() < settleUntil) {
          settleRAF = requestAnimationFrame(tick);
        } else {
          cancelAnimationFrame(settleRAF); settleRAF = 0;
          alignCanvasToVideo();
        }
      };
      tick();
    }

    // Keep aligned as environment changes
    ['resize','orientationchange','scroll'].forEach(ev =>
      window.addEventListener(ev, () => beginViewportSettle(), { passive: true })
    );
    if (window.visualViewport) {
      ['resize','scroll'].forEach(ev =>
        window.visualViewport.addEventListener(ev, () => beginViewportSettle(), { passive: true })
      );
    }
    document.addEventListener('visibilitychange', () => {
      if (!document.hidden) beginViewportSettle();
    });

    // ---------- Drawing ----------
    function setOverlayVisible(v) {
      poseCanvas.style.display = v ? 'block' : 'none';
      if (v) beginViewportSettle();
      else poseCtx.clearRect(0,0, poseCanvas.width, poseCanvas.height);
    }
    function drawPoseLandmarks(landmarks) {
      if (!poseEnabled || poseWhere !== 'sender') return;
      if (!landmarks?.length || !poseCanvas.width || !poseCanvas.height) return;

      poseCtx.save();
      poseCtx.clearRect(0,0, poseCanvas.width, poseCanvas.height);

      const utils = new DrawingUtils(poseCtx);
      for (const lm of landmarks) {
        utils.drawLandmarks(lm, {
          radius: (data) => DrawingUtils.lerp((data.from && data.from.z) ?? 0, -0.15, 0.1, 5, 1)
        });
        utils.drawConnectors(lm, PoseLandmarker.POSE_CONNECTIONS);
      }
      poseCtx.restore();
    }

    // ---------- WebSocket / WebRTC ----------
    let wsKeepaliveId;
    async function connectWS() {
      return new Promise((resolve, reject) => {
        const url = `${WS_ENDPOINT}?room=${encodeURIComponent(room)}`;
        showStatus('Connecting to signaling…');
        const sock = new WebSocket(url);
        ws = sock;

        let opened = false;
        const openTimeout = setTimeout(() => {
          if (!opened) { try { sock.close(); } catch{}; reject(new Error('WS timeout')); }
        }, 15000);

        sock.onopen = () => {
          opened = true; clearTimeout(openTimeout);
          showStatus('Signaling: connected');
          wsRetryMs = WS_RECONNECT_MIN_MS;
          send({ type: 'join', room });

          if (wsKeepalive) clearInterval(wsKeepalive);
          wsKeepalive = setInterval(() => {
            if (ws?.readyState === WebSocket.OPEN) send({ type:'keepalive', ts: Date.now() });
          }, WS_KEEPALIVE_MS);

          resolve();
        };
        sock.onmessage = onSignal;
        sock.onerror = (e) => { console.warn('[WS error]', e); };
        sock.onclose  = () => {
          showStatus('Signaling: closed');
          if (wsKeepalive) { clearInterval(wsKeepalive); wsKeepalive = null; }
          scheduleWSReconnect();
        };
      });
    }
    function scheduleWSReconnect() {
      const delay = Math.min(wsRetryMs, WS_RECONNECT_MAX_MS);
      console.log('[WS] reconnect in', delay,'ms');
      setTimeout(() => {
        wsRetryMs = Math.min(wsRetryMs * 2, WS_RECONNECT_MAX_MS);
        startNegotiation();
      }, delay);
    }
    const send = (obj) => { try { ws?.readyState === WebSocket.OPEN && ws.send(JSON.stringify(obj)); } catch {} };

    function createPC() {
      if (pc) { try { pc.close(); } catch{}; pc = null; }
      remoteDescriptionSet = false;
      lastAnswerSdp = null;
      candidateQueue.length = 0;

      pc = new RTCPeerConnection({ iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] });

      pc.addTransceiver('video', { direction: 'recvonly' });
      pc.addTransceiver('audio', { direction: 'recvonly' });

      // Pose DC (receiver initiates)
      const ch = pc.createDataChannel('pose');
      ch.onopen = () => { console.log('[DC][receiver] pose DC open'); };
      ch.onclose = () => { console.log('[DC][receiver] pose DC close'); };
      ch.onerror = (e) => { console.warn('[DC][receiver] pose DC error', e); };
      ch.onmessage = (ev) => {
        try {
          const msg = JSON.parse(ev.data);
          if (msg.type === 'pose-mode') {
            poseEnabled = !!msg.enabled;
            poseWhere   = msg.where || 'sender';
            console.log('[POSE][receiver] mode:', { poseEnabled, poseWhere });
            setOverlayVisible(poseEnabled && poseWhere === 'sender');
            if (!(poseEnabled && poseWhere === 'sender')) {
              poseCtx.clearRect(0,0, poseCanvas.width, poseCanvas.height);
            }
          } else if (msg.type === 'pose') {
            if (poseEnabled && poseWhere === 'sender') drawPoseLandmarks(msg.landmarks);
          }
        } catch {}
      };
      poseDC = ch;

      pc.onicecandidate = (ev) => { if (ev.candidate) send({ type:'candidate', candidate: ev.candidate }); };
      pc.ontrack = (ev) => {
        if (remoteVideo.srcObject !== ev.streams[0]) {
          remoteVideo.srcObject = ev.streams[0];
          tryStartMuted();
        }
        console.log('[TRACK][receiver] ontrack:', ev.track.kind);
        beginViewportSettle(); // align when media arrives
      };

      pc.oniceconnectionstatechange = () => {
        const state = pc.iceConnectionState;
        console.log('[ICE]', state);
        if (state === 'connected') showStatus('Connected'); else showStatus('ICE: ' + state);

        if (state === 'disconnected') {
          if (!iceDisconnectedSince) iceDisconnectedSince = Date.now();
          setTimeout(() => {
            if (iceDisconnectedSince && Date.now() - iceDisconnectedSince >= RESTART_ON_ICE_TIMEOUT_MS) {
              console.log('[ICE] disconnected timeout - restarting negotiation');
              startNegotiation(true);
            }
          }, RESTART_ON_ICE_TIMEOUT_MS + 50);
        } else if (state === 'failed') {
          console.log('[ICE] failed - restarting negotiation');
          startNegotiation(true);
        } else {
          iceDisconnectedSince = null;
        }
      };
    }

    async function sendCurrentOffer() {
      if (pc?.localDescription?.type === 'offer') {
        console.log('[WS OUT] offer (send/resend)');
        send(pc.localDescription);
      }
    }
    function startOfferResendLoop() {
      stopOfferResendLoop();
      offerResendTimer = setInterval(() => {
        if (!remoteDescriptionSet) sendCurrentOffer();
        else stopOfferResendLoop();
      }, 2000);
    }
    function stopOfferResendLoop() {
      if (offerResendTimer) clearInterval(offerResendTimer);
      offerResendTimer = null;
    }

    async function startNegotiation(forceNewPc = false) {
      if (!ws || ws.readyState !== WebSocket.OPEN) {
        try { await connectWS(); } catch(e) { scheduleWSReconnect(); return; }
      }
      if (!pc || forceNewPc) createPC();

      try {
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        await sendCurrentOffer();
        startOfferResendLoop();
        showStatus('Offer sent, waiting for answer…');
      } catch (e) {
        console.error('negotiation error', e);
        showStatus('Negotiation error');
      }
    }

    async function onSignal(evt) {
      let msg; try { msg = JSON.parse(evt.data); } catch { return; }
      console.log('[WS IN]', msg.type);

      if (msg.type === 'answer') {
        if (pc.signalingState !== 'have-local-offer') {
          console.log('[SKIP] answer in state', pc.signalingState);
          return;
        }
        if (lastAnswerSdp === msg.sdp) { console.log('[DUP] identical answer ignored'); return; }
        lastAnswerSdp = msg.sdp;

        showStatus('Got answer, applying…');
        await pc.setRemoteDescription(new RTCSessionDescription(msg));
        remoteDescriptionSet = true;
        stopOfferResendLoop();

        for (const c of candidateQueue) {
          try { await pc.addIceCandidate(c); } catch (e) { console.warn('late ICE add failed', e); }
        }
        candidateQueue.length = 0;

      } else if (msg.type === 'candidate' && msg.candidate) {
        const cand = new RTCIceCandidate(msg.candidate);
        if (remoteDescriptionSet) {
          try { await pc.addIceCandidate(cand); } catch (e) { console.warn('ICE add failed', e); }
        } else {
          candidateQueue.push(cand);
        }

      } else if (msg.type === 'peer-joined' || msg.type === 'need-offer') {
        await sendCurrentOffer();
      } else if (msg.type === 'bye') {
        console.log('[INFO] sender bye -> keep re-offering');
        remoteDescriptionSet = false;
        startOfferResendLoop();
      }
    }

    window.addEventListener('beforeunload', () => {
      try { stopOfferResendLoop(); } catch {}
      try { ws && ws.close(); } catch {}
      try { pc && pc.close(); } catch {}
      if (wsKeepalive) clearInterval(wsKeepalive);
      if (hideStatusTimer) clearTimeout(hideStatusTimer);
    });

    // Go!
    startNegotiation();
  </script>
</body>
</html>
