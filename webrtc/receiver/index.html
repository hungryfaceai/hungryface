<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Baby Monitor – Receiver</title>
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"/>
  <style>
    :root { color-scheme: dark; }
    html, body { margin: 0; height: 100%; background: #000; color: #ccc; font-family: -apple-system, system-ui, Segoe UI, Roboto, sans-serif; touch-action: manipulation; }
    #stage { position: fixed; inset: 0; z-index: 1; }
    #stage > video#local { position: absolute; inset: 0; width: 100vw; height: 100vh; object-fit: contain; background: #000; display: none; pointer-events: none; }
    #stage > canvas#poseCanvas { position: absolute; display: none; background: transparent; pointer-events: none; }
    .mirror #local, .mirror #poseCanvas { transform: scaleX(-1); }
    #ui { position: relative; z-index: 5; min-height: 100%; display: flex; align-items: center; justify-content: center; padding: 20px; }
    .card { width: 100%; max-width: 520px; background: #0b0b0b; border: 1px solid #141414; border-radius: 14px; padding: 18px; box-sizing: border-box; }
    .row { display: flex; align-items: center; justify-content: space-between; gap: 12px; margin: 10px 0; }
    label.switch { display: flex; align-items: center; gap: 10px; font-size: 16px; }
    input[type="checkbox"] { width: 22px; height: 22px; }
    input[type="text"], select, input[type="number"] { width: 100%; padding: 10px 12px; border-radius: 10px; border: 1px solid #222; background:#0b0b0b; color:#ddd; -moz-appearance:textfield; }
    #cameraSel { font-size: 18px; padding: 14px 16px; height: 52px; border-radius: 12px; }
    input[type="number"]::-webkit-outer-spin-button, input[type="number"]::-webkit-inner-spin-button { -webkit-appearance: none; margin: 0; }
    button { width: 100%; padding: 14px 16px; border-radius: 12px; border: 0; background: #2a2a2a; color: #fff; font-size: 17px; font-weight: 600; cursor: pointer; }
    button:active { transform: scale(0.99); }
    .overlay { position: fixed; inset: 0; display: none; align-items: center; justify-content: center; pointer-events: none; z-index: 4; }
    body.streaming .overlay, body.previewing .overlay { display: flex; }
    .status { background: rgba(255,255,255,0.05); border: 1px solid rgba(255,255,255,0.1); color: #ddd; font-size: 14px; padding: 10px 14px; border-radius: 12px; text-align: center; white-space: pre-line; max-width: 90vw; }
    #tap { position: fixed; inset: 0; display: none; z-index: 6; }
    body.streaming:not(.ui-visible) #tap { display: block; }
    body.streaming:not(.ui-visible) #ui { display: none; }
    body.blackout { background: #000; }
    fieldset.ai { border: 1px solid #222; border-radius: 12px; padding: 10px 12px; }
    fieldset.ai legend { padding: 0 6px; color: #bbb; }
    .ai-row { display: grid; grid-template-columns: 1fr 140px; gap: 8px; align-items: center; margin: 10px 0; }
    .ai-row select { width: 100%; padding: 8px 10px; border-radius: 10px; border: 1px solid #222; background:#0b0b0b; color:#ddd; }
  </style>
</head>
<body class="blackout">
  <div id="stage">
    <!-- Will show the REMOTE stream -->
    <video id="local" playsinline autoplay muted></video>
    <canvas id="poseCanvas"></canvas>
  </div>

  <div id="ui">
    <div class="card">
      <h2 style="margin:0 0 8px 0;">Camera Receiver</h2>

      <!-- Keep controls for consistency; on receiver they affect playback (video visibility/mute), not capture -->
      <div class="row">
        <label class="switch"><input id="videoOn" type="checkbox" checked><span>Video ON</span></label>
        <label class="switch"><input id="audioOn" type="checkbox" checked><span>Audio ON</span></label>
      </div>

      <div class="row">
        <select id="cameraSel" aria-label="Camera">
          <option value="environment" selected>Back camera</option>
          <option value="user">Front camera</option>
        </select>
      </div>

      <div class="row">
        <input id="room" type="text" placeholder="Room (e.g., Baby)" value="Baby" autocomplete="off">
      </div>

      <div class="row">
        <input id="previewMins" type="number" min="0" step="1" value="1" aria-label="Preview minutes">
        <span style="opacity:.7;font-size:13px;">Preview minutes</span>
      </div>

      <fieldset class="ai">
        <legend>AI features</legend>
        <!-- On receiver, these are only to display the current mode in UI; actual mode comes from sender via DC -->
        <div class="ai-row">
          <label class="switch"><input id="poseOn" type="checkbox"><span>Pose</span></label>
          <select id="poseWhere">
            <option value="sender" selected>On sender</option>
            <option value="receiver">On receiver</option>
          </select>
        </div>
        <div class="ai-row">
          <label class="switch"><input type="checkbox" disabled><span>Audio</span></label>
          <select disabled><option>On sender</option><option>On receiver</option></select>
        </div>
        <div class="ai-row">
          <label class="switch"><input type="checkbox" disabled><span>Face</span></label>
          <select disabled><option>On sender</option><option>On receiver</option></select>
        </div>
      </fieldset>

      <div class="row" style="margin-top:14px;">
        <button id="startBtn">Start</button>
      </div>
    </div>
  </div>

  <div id="tap" aria-hidden="true"></div>
  <div class="overlay"><div class="status" id="status">Idle</div></div>

  <script type="module">
    /* ------------------ Config ------------------ */
    const WS_ENDPOINT = "wss://signaling-server-f5gu.onrender.com/ws";
    const UI_AUTOHIDE_MS = 10000;
    const NEED_OFFER_INTERVAL_MS = 3000;
    const TASKS_URL  = "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.20.1";
    const WASM_DIR   = TASKS_URL + "/wasm";

    /* ------------------ DOM ------------------ */
    const roomInput = document.getElementById('room');
    const videoOn   = document.getElementById('videoOn');
    const audioOn   = document.getElementById('audioOn');
    const cameraSel = document.getElementById('cameraSel'); // UI only (mirroring)
    const previewMinsInput = document.getElementById('previewMins');
    const startBtn  = document.getElementById('startBtn');
    const localVideo= document.getElementById('local'); // shows REMOTE
    const poseCanvas= document.getElementById('poseCanvas');
    const statusEl  = document.getElementById('status');
    const ui        = document.getElementById('ui');

    const poseOn    = document.getElementById('poseOn');
    const poseWhere = document.getElementById('poseWhere');

    /* ------------------ State ------------------ */
    let ws = null, pc = null, started = false, hideUITimer = null;
    let remoteDescriptionSet = false;
    const candidateQueue = [];
    let needOfferTimer = null;

    let previewTimer = null, previewTicker = null, previewEnd = 0;

    // Receiver creates the 'pose' data channel
    let poseDC = null;

    let PoseLandmarker, FilesetResolver, DrawingUtils;
    let poseTask = null, poseLoopRunning = false;
    const ctx = poseCanvas.getContext('2d', { alpha: true });

    /* ------------------ Logging helpers ------------------ */
    const log = (...a) => console.log('[RECEIVER]', ...a);
    const rlog = (tag, ...a) => console.log(`[RECEIVER][${tag}]`, ...a);
    const setStatus = (t) => { statusEl.textContent = t; rlog('STATUS', t); };

    /* ------------------ Helpers ------------------ */
    const currentRoom = () => (roomInput.value || 'Baby').trim();
    const isFront = () => (cameraSel.value === 'user');
    function updateMirrorClass() { document.body.classList.toggle('mirror', isFront()); }

    function calcViewportContainRect() {
      const vw = window.innerWidth, vh = window.innerHeight;
      const vidW = localVideo.videoWidth || 1, vidH = localVideo.videoHeight || 1;
      const scale = Math.min(vw / vidW, vh / vidH);
      const w = vidW * scale, h = vidH * scale;
      const x = (vw - w) / 2, y = (vh - h) / 2;
      return { x, y, width:w, height:h, left:x, top:y };
    }

    function resizeCanvasToVideo() {
      const showVideo = document.body.classList.contains('previewing') && videoOn.checked;
      localVideo.style.display = showVideo ? 'block' : 'none';

      let rect = localVideo.getBoundingClientRect();
      if (!rect.width || !rect.height) rect = calcViewportContainRect();

      Object.assign(poseCanvas.style, {
        left: rect.left + 'px', top: rect.top + 'px',
        width: rect.width + 'px', height: rect.height + 'px'
      });

      const dpr = window.devicePixelRatio || 1;
      poseCanvas.width  = Math.max(1, Math.round(rect.width  * dpr));
      poseCanvas.height = Math.max(1, Math.round(rect.height * dpr));
      poseCanvas.style.display =
        (poseOn.checked && videoOn.checked && document.body.classList.contains('previewing'))
          ? 'block' : 'none';

      ctx.setTransform(1,0,0,1,0,0);
      rlog('LAYOUT', 'resizeCanvasToVideo', {rect, dpr});
    }

    localVideo.addEventListener('loadedmetadata', () => {
      rlog('MEDIA', 'remote video meta', localVideo.videoWidth, 'x', localVideo.videoHeight);
      resizeCanvasToVideo();
    });
    ['resize','orientationchange','scroll'].forEach(ev =>
      window.addEventListener(ev, () => {
        if (document.body.classList.contains('previewing')) resizeCanvasToVideo();
      })
    );
    if (window.visualViewport) {
      ['resize','scroll'].forEach(ev =>
        window.visualViewport.addEventListener(ev, () => {
          if (document.body.classList.contains('previewing')) resizeCanvasToVideo();
        })
      );
    }

    // On receiver, toggles affect playback/visibility only
    function applyVideoToggle() {
      resizeCanvasToVideo();
      setStatus(videoOn.checked ? 'Video ON' : 'Video OFF');
    }
    function applyAudioToggle() {
      localVideo.muted = !audioOn.checked; // mute/unmute playback
      setStatus(audioOn.checked ? 'Audio ON' : 'Audio OFF');
    }
    videoOn.addEventListener('change', applyVideoToggle);
    audioOn.addEventListener('change', applyAudioToggle);
    cameraSel.addEventListener('change', () => { updateMirrorClass(); resizeCanvasToVideo(); });

    /* ------------------ Signaling ------------------ */
    function connectWS(room) {
      return new Promise((resolve, reject) => {
        const url = `${WS_ENDPOINT}?room=${encodeURIComponent(room)}`;
        setStatus('Connecting to signaling…');
        const sock = new WebSocket(url);
        ws = sock;

        let opened = false;
        const t = setTimeout(() => {
          if (!opened) { try { sock.close(); } catch{}; setStatus('Signaling: timeout'); reject(new Error('WS timeout')); }
        }, 15000);

        sock.onopen = () => {
          opened = true; clearTimeout(t);
          setStatus('Signaling: connected');
          send({ type: 'join', room });
          resolve();
        };
        sock.onmessage = onSignal;
        sock.onerror = (e) => { rlog('WS', 'error', e); };
        sock.onclose  = (e) => { rlog('WS', 'closed', e.code, e.reason); setStatus('Signaling: closed'); };
      });
    }
    const send = (obj) => { try { ws?.readyState === WebSocket.OPEN && ws.send(JSON.stringify(obj)); } catch {} };

    function createPC() {
      pc = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
        bundlePolicy: 'max-bundle',
        sdpSemantics: 'unified-plan'
      });

      // We expect to RECEIVE tracks
      pc.addTransceiver('video', { direction: 'recvonly' });
      pc.addTransceiver('audio', { direction: 'recvonly' });

      // Data channel for pose (receiver creates it)
      poseDC = pc.createDataChannel('pose');
      rlog('DC', 'createDataChannel: pose');
      poseDC.onopen = () => { rlog('POSE', 'DC open (receiver side)'); };
      poseDC.onclose = () => { rlog('POSE', 'DC close (receiver side)'); };
      poseDC.onerror = (e) => { rlog('POSE', 'DC error', e); };
      poseDC.onmessage = onPoseMessageFromSenderOrControl;

      pc.onicecandidate = (e) => { if (e.candidate) send({ type: 'candidate', candidate: e.candidate }); };
      pc.oniceconnectionstatechange = () => setStatus('ICE: ' + pc.iceConnectionState);

      pc.ontrack = (ev) => {
        rlog('TRACK', 'ontrack', ev.track.kind);
        const [stream] = ev.streams;
        if (stream) {
          // Attach the remote stream to the existing <video id="local">
          // (keeps DOM/behavior the same)
          localVideo.srcObject = stream;
          // let autoplay happen; audio mute controlled by audioOn
          applyAudioToggle();
        }
      };
    }

    async function makeOfferIfNeeded() {
      if (!pc) createPC();
      const offer = await pc.createOffer({ offerToReceiveAudio: true, offerToReceiveVideo: true });
      await pc.setLocalDescription(offer);
      send(offer);
      rlog('SDP', 'offer sent');
    }

    async function onSignal(evt) {
      let msg; try { msg = JSON.parse(evt.data); } catch { return; }
      rlog('WS IN', msg.type);

      if (msg.type === 'need-offer') {
        // Sender is ready to answer → create/send offer
        await makeOfferIfNeeded();

      } else if (msg.type === 'answer') {
        await pc.setRemoteDescription(new RTCSessionDescription(msg));
        remoteDescriptionSet = true;
        rlog('SDP', 'answer applied');

        // Apply queued ICE
        while (candidateQueue.length) {
          const c = candidateQueue.shift();
          try { await pc.addIceCandidate(c); } catch (err) { rlog('ICE', 'late ICE add failed', err); }
        }

      } else if (msg.type === 'candidate' && msg.candidate) {
        const cand = new RTCIceCandidate(msg.candidate);
        if (pc && pc.remoteDescription) {
          try { await pc.addIceCandidate(cand); } catch (err) { rlog('ICE', 'add failed', err); }
        } else {
          candidateQueue.push(cand);
        }
      }
    }

    /* ------------------ Preview / UI ------------------ */
    function beginPreviewWindow(minutes) {
      const ms = Math.max(0, Math.round((Number(minutes) || 1) * 60000));
      if (ms === 0) { enterBlackout(); return; }

      document.body.classList.remove('blackout');
      document.body.classList.add('previewing');
      document.body.classList.add('streaming');
      document.body.classList.remove('ui-visible');

      resizeCanvasToVideo();

      previewEnd = Date.now() + ms;
      tickPreviewCountdown();
      previewTicker = setInterval(tickPreviewCountdown, 1000);
      previewTimer  = setTimeout(endPreviewNow, ms);
    }
    function tickPreviewCountdown() {
      const remain = Math.max(0, previewEnd - Date.now());
      const sec = Math.ceil(remain / 1000);
      const mm = String(Math.floor(sec / 60)).padStart(2,'0');
      const ss = String(sec % 60).padStart(2,'0');
      setStatus(`Preview ends in ${mm}:${ss}`);
    }
    function endPreviewNow() {
      if (previewTimer) clearTimeout(previewTimer);
      if (previewTicker) clearInterval(previewTicker);
      previewTimer = previewTicker = null;
      enterBlackout();
    }
    function enterBlackout() {
      document.body.classList.remove('previewing');
      document.body.classList.add('streaming');
      document.body.classList.remove('ui-visible');
      localVideo.style.display = 'none';
      poseCanvas.style.display = 'none';
      setStatus('Streaming...');
      clearTimeout(hideUITimer); hideUITimer = null;
    }

    document.addEventListener('click', (e) => {
      if (document.body.classList.contains('previewing')) { endPreviewNow(); return; }
      if (document.body.classList.contains('streaming') && !document.body.classList.contains('ui-visible')) {
        document.body.classList.add('ui-visible'); setStatus('Streaming...'); scheduleAutoHideUI(); return;
      }
      if (document.body.classList.contains('streaming') && document.body.classList.contains('ui-visible')) {
        const inCard = e.target.closest('.card');
        if (!inCard) { document.body.classList.remove('ui-visible'); setStatus('Streaming...'); clearTimeout(hideUITimer); hideUITimer = null; }
      }
    });
    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape') {
        if (document.body.classList.contains('previewing')) { endPreviewNow(); }
        else if (document.body.classList.contains('streaming') && document.body.classList.contains('ui-visible')) {
          document.body.classList.remove('ui-visible'); setStatus('Streaming...'); clearTimeout(hideUITimer); hideUITimer = null;
        }
      }
    });
    function scheduleAutoHideUI() {
      clearTimeout(hideUITimer);
      hideUITimer = setTimeout(() => {
        if (document.body.classList.contains('streaming')) {
          document.body.classList.remove('ui-visible');
          setStatus('Streaming...');
        }
      }, UI_AUTOHIDE_MS);
    }

    /* ------------------ Start/Stop ------------------ */
    async function startOrStop() {
      try {
        if (started) { await stopStreaming(); return; }

        startBtn.disabled = true;

        updateMirrorClass();
        const room = currentRoom();

        setStatus('Connecting…');
        await connectWS(room);

        // Prepare PC and request an offer cycle
        createPC();
        // Proactively ask sender to request an offer from us (we will generate on need-offer)
        send({ type: 'need-offer' });
        needOfferTimer = setInterval(() => {
          if (!remoteDescriptionSet) { rlog('WS OUT', 'need-offer (retry)'); send({ type: 'need-offer' }); }
          else { clearInterval(needOfferTimer); needOfferTimer = null; }
        }, NEED_OFFER_INTERVAL_MS);

        // UI/preview window behavior remains the same
        beginPreviewWindow(Number(previewMinsInput.value) || 1);

        started = true;
        startBtn.textContent = 'Stop';
        startBtn.disabled = false;

        applyVideoToggle();
        applyAudioToggle();

      } catch (err) {
        console.error(err);
        alert(err.message || err);
        setStatus('Idle');
        startBtn.disabled = false;
      }
    }

    async function stopStreaming() {
      try { send({ type: 'bye' }); } catch {}

      if (previewTimer) clearTimeout(previewTimer);
      if (previewTicker) clearInterval(previewTicker);
      if (hideUITimer) clearTimeout(hideUITimer);
      if (needOfferTimer) clearInterval(needOfferTimer);
      previewTimer = previewTicker = hideUITimer = needOfferTimer = null;

      try { poseLoopRunning = false; } catch {}
      try { poseTask && poseTask.close && poseTask.close(); } catch {}
      poseTask = null;

      try { pc && pc.close(); } catch {}
      try { ws && ws.close(); } catch {}

      poseDC = null;

      pc = null; ws = null;
      started = false;

      remoteDescriptionSet = false;
      candidateQueue.length = 0;

      document.body.classList.remove('previewing','streaming','ui-visible');
      document.body.classList.add('blackout');

      ui.style.display = '';
      localVideo.style.display = 'none';
      poseCanvas.style.display = 'none';
      ctx.clearRect(0,0,poseCanvas.width, poseCanvas.height);

      setStatus('Stopped');
      startBtn.textContent = 'Start';
    }

    window.addEventListener('beforeunload', stopStreaming);
    startBtn.addEventListener('click', startOrStop);

    /* ------------------ Pose: receiver behavior ------------------ */
    async function loadVision() {
      if (PoseLandmarker) return;
      const mod = await import(TASKS_URL);
      const vision = mod.default || mod;
      ({ PoseLandmarker, FilesetResolver, DrawingUtils } = vision);
      rlog('POSE', 'tasks-vision loaded', { version: '0.20.1' });
    }
    async function ensurePoseTask() {
      await loadVision();
      if (poseTask) return poseTask;
      const visionFS = await FilesetResolver.forVisionTasks(WASM_DIR);
      poseTask = await PoseLandmarker.createFromOptions(visionFS, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numPoses: 1
      });
      rlog('POSE', 'pose task created');
      return poseTask;
    }

    function drawPoseOnReceiver(landmarks) {
      if (!landmarks?.length || !poseCanvas.width || !poseCanvas.height) {
        rlog('POSE', 'draw skip (no landmarks or canvas not visible)');
        return;
      }
      const dutils = new DrawingUtils(ctx);
      ctx.save();
      ctx.clearRect(0,0, poseCanvas.width, poseCanvas.height);
      for (const lm of landmarks) {
        dutils.drawLandmarks(lm, { radius: (data) => DrawingUtils.lerp((data.from && data.from.z) ?? 0, -0.15, 0.1, 5, 1) });
        dutils.drawConnectors(lm, PoseLandmarker.POSE_CONNECTIONS);
      }
      ctx.restore();
    }

    function sendPoseBackToSender(landmarks) {
      if (poseDC?.readyState === 'open') {
        poseDC.send(JSON.stringify({ type:'pose', landmarks, ts: performance.now() }));
      }
    }

    async function startReceiverPoseLoop() {
      // Only run if UI says Pose ON AND where === receiver
      if (!started || !poseOn.checked || poseWhere.value !== 'receiver') {
        rlog('POSE', 'startReceiverPoseLoop skipped (not enabled or wrong mode)');
        return;
      }
      const task = await ensurePoseTask();
      poseLoopRunning = true;
      rlog('POSE', 'inference START (receiver)');
      const loop = async () => {
        if (!poseLoopRunning || !started || !poseOn.checked || poseWhere.value !== 'receiver') {
          rlog('POSE', 'inference STOP (receiver)');
          return;
        }
        const ts = performance.now();
        const result = task.detectForVideo(localVideo, ts);
        ctx.clearRect(0,0, poseCanvas.width, poseCanvas.height);
        if (result?.landmarks?.length) {
          if (document.body.classList.contains('previewing')) {
            drawPoseOnReceiver(result.landmarks);
          } else {
            rlog('POSE', 'not drawing (not in preview), but echoing to sender');
          }
          // Always echo back so sender can draw during its preview
          sendPoseBackToSender(result.landmarks);
        }
        requestAnimationFrame(loop);
      };
      loop();
    }

    function stopReceiverPoseLoop() {
      poseLoopRunning = false;
      ctx.clearRect(0,0, poseCanvas.width, poseCanvas.height);
    }

    function onPoseMessageFromSenderOrControl(ev) {
      try {
        const msg = JSON.parse(ev.data);
        if (msg.type === 'pose-mode') {
          // Reflect in UI; sender is the source of truth
          poseOn.checked = !!msg.enabled;
          poseWhere.value = msg.where || 'sender';
          rlog('POSE', 'control', msg);
          if (!poseOn.checked) {
            stopReceiverPoseLoop();
          } else if (poseWhere.value === 'receiver') {
            startReceiverPoseLoop();
          } else {
            // where: sender → we will only draw what the sender sends
            stopReceiverPoseLoop();
          }
          // Also update layout (visibility condition uses these flags)
          resizeCanvasToVideo();
        } else if (msg.type === 'pose') {
          // Sender ran inference and sent landmarks → draw if previewing
          if (document.body.classList.contains('previewing')) {
            drawPoseOnReceiver(msg.landmarks);
          } else {
            rlog('POSE', 'received landmarks but not in preview → not drawing');
          }
        }
      } catch (e) {
        rlog('POSE', 'bad message', e);
      }
    }

    function applyPoseUI() {
      // On receiver, UI switches are informational; real control comes from sender.
      // Still respect them so local testing works.
      resizeCanvasToVideo();
      if (!poseOn.checked) { stopReceiverPoseLoop(); return; }
      if (started && poseWhere.value === 'receiver') startReceiverPoseLoop();
      else stopReceiverPoseLoop();
    }
    poseOn.addEventListener('change', () => { rlog('POSE', 'UI change', {enabled: poseOn.checked, where: poseWhere.value}); applyPoseUI(); });
    poseWhere.addEventListener('change', () => { rlog('POSE', 'UI change', {enabled: poseOn.checked, where: poseWhere.value}); applyPoseUI(); });

    /* ------------------ Init ------------------ */
    const qsRoom = new URLSearchParams(location.search).get('room');
    if (qsRoom) roomInput.value = qsRoom;
  </script>
</body>
</html>
