<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Baby Monitor – Sender</title>
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"/>
  <style>
    :root { color-scheme: dark; }
    html, body {
      margin: 0; height: 100%;
      background: #000; color: #ccc; font-family: -apple-system, system-ui, Segoe UI, Roboto, sans-serif;
      touch-action: manipulation;
    }
    #ui { min-height: 100%; display: flex; align-items: center; justify-content: center; padding: 20px; }
    .card {
      width: 100%; max-width: 560px;
      background: #0b0b0b; border: 1px solid #141414; border-radius: 14px;
      padding: 18px; box-sizing: border-box;
    }
    .row { display: flex; align-items: center; justify-content: space-between; gap: 12px; margin: 10px 0; }
    label.switch { display: flex; align-items: center; gap: 10px; font-size: 16px; }
    input[type="checkbox"] { width: 22px; height: 22px; }
    input[type="text"], select, input[type="number"] {
      width: 100%; padding: 12px 14px; border-radius: 10px; border: 1px solid #222; background:#0b0b0b; color:#ddd;
      -moz-appearance:textfield;
    }
    /* Larger camera dropdown */
    #cameraSel {
      font-size: 18px; padding: 14px 16px; height: 52px; border-radius: 12px;
    }
    input[type="number"]::-webkit-outer-spin-button,
    input[type="number"]::-webkit-inner-spin-button { -webkit-appearance: none; margin: 0; }
    button {
      width: 100%; padding: 14px 16px; border-radius: 12px; border: 0;
      background: #2a2a2a; color: #fff; font-size: 17px; font-weight: 600;
      cursor: pointer;
    }
    button:active { transform: scale(0.99); }

    /* AI features group */
    fieldset.ai {
      margin-top: 12px; border: 1px solid #222; border-radius: 12px; padding: 12px;
    }
    fieldset.ai legend { padding: 0 8px; color: #bbb; }
    .ai-row {
      display: grid; grid-template-columns: 1fr auto; align-items: center; gap: 12px;
      padding: 6px 0;
    }
    .ai-row + .ai-row { border-top: 1px solid #161616; }

    /* Local video + overlay (only visible during preview/UI) */
    video#local {
      display: none;
      position: fixed; inset: 0;
      width: 100vw; height: 100vh;
      object-fit: contain; background: #000; z-index: 1;
      transform-origin: center center;
    }
    canvas#poseCanvas {
      display: none;
      position: fixed; z-index: 2; pointer-events: none;
      /* left/top/size are set in JS to match letterboxed video rect */
    }
    body.previewing video#local { display: block; }
    body.previewing canvas#poseCanvas { display: block; }
    body.streaming.ui-visible video#local { display: block; }
    body.streaming.ui-visible canvas#poseCanvas { display: block; }

    body.blackout { background: #000; }
    body.streaming.ui-visible .overlay { display: none !important; }
    .overlay { position: fixed; inset: 0; display: none; align-items: center; justify-content: center; pointer-events: none; z-index: 3; }
    body.streaming .overlay, body.previewing .overlay { display: flex; }
    .status {
      background: rgba(255,255,255,0.05);
      border: 1px solid rgba(255,255,255,0.1);
      color: #ddd; font-size: 14px; padding: 10px 14px; border-radius: 12px;
      text-align: center; white-space: pre-line;
    }
    #tap { position: fixed; inset: 0; display: none; z-index: 4; }
    body.streaming:not(.ui-visible) #tap { display: block; }
    body.streaming:not(.ui-visible) #ui { display: none; }
  </style>
</head>
<body class="blackout">
  <div id="ui">
    <div class="card">
      <h2 style="margin:0 0 8px 0;">Camera Sender</h2>

      <div class="row">
        <label class="switch">
          <input id="videoOn" type="checkbox" checked>
          <span>Video ON</span>
        </label>
        <label class="switch">
          <input id="audioOn" type="checkbox" checked>
          <span>Audio ON</span>
        </label>
      </div>

      <div class="row">
        <select id="cameraSel" aria-label="Camera">
          <option value="environment" selected>Back camera</option>
          <option value="user">Front camera</option>
        </select>
      </div>

      <div class="row">
        <input id="room" type="text" placeholder="Room (e.g., Baby)" value="Baby" autocomplete="off">
      </div>

      <div class="row">
        <input id="previewMins" type="number" min="0" step="1" value="1" aria-label="Preview minutes">
        <span style="opacity:.7;font-size:13px;">Preview minutes</span>
      </div>

      <!-- AI features -->
      <fieldset class="ai">
        <legend>AI features</legend>

        <div class="ai-row">
          <label class="switch"><input id="cbAudioAI" type="checkbox" disabled> <span>Audio</span></label>
          <select id="selAudioAI" disabled>
            <option value="sender">On sender</option>
            <option value="receiver">On receiver</option>
          </select>
        </div>

        <div class="ai-row">
          <label class="switch"><input id="cbPose" type="checkbox"> <span>Pose</span></label>
          <select id="selPose">
            <option value="sender">On sender</option>
            <option value="receiver">On receiver</option>
          </select>
        </div>

        <div class="ai-row">
          <label class="switch"><input id="cbFace" type="checkbox" disabled> <span>Face</span></label>
          <select id="selFace" disabled>
            <option value="sender">On sender</option>
            <option value="receiver">On receiver</option>
          </select>
        </div>
      </fieldset>

      <div class="row" style="margin-top:14px;">
        <button id="startBtn">Start streaming</button>
      </div>
    </div>
  </div>

  <div id="tap" aria-hidden="true"></div>
  <div class="overlay"><div class="status" id="status">Idle</div></div>

  <!-- local preview & overlay -->
  <video id="local" playsinline autoplay muted></video>
  <canvas id="poseCanvas"></canvas>

  <script>
    /* ================== Config / elements ================== */
    const WS_ENDPOINT = "wss://signaling-server-f5gu.onrender.com/ws";
    const UI_AUTOHIDE_MS = 10000;
    const NEED_OFFER_INTERVAL_MS = 3000;

    const qsRoom = new URLSearchParams(location.search).get('room');
    const roomInput = document.getElementById('room');
    if (qsRoom) roomInput.value = qsRoom;

    const videoOn   = document.getElementById('videoOn');
    const audioOn   = document.getElementById('audioOn');
    const cameraSel = document.getElementById('cameraSel');
    const previewMinsInput = document.getElementById('previewMins');
    const startBtn  = document.getElementById('startBtn');
    const localVideo= document.getElementById('local');
    const statusEl  = document.getElementById('status');
    const ui        = document.getElementById('ui');
    const tap       = document.getElementById('tap');

    // AI controls
    const cbAudioAI = document.getElementById('cbAudioAI');
    const selAudioAI = document.getElementById('selAudioAI');
    const cbPose   = document.getElementById('cbPose');
    const selPose  = document.getElementById('selPose');
    const cbFace   = document.getElementById('cbFace');
    const selFace  = document.getElementById('selFace');

    // pose overlay
    const poseCanvas = document.getElementById('poseCanvas');
    const poseCtx    = poseCanvas.getContext('2d');

    /* ================== State ================== */
    let ws=null, pc=null, poseDC=null, localStream=null;
    let wakeLock=null;
    let previewTimer=null, previewTicker=null, previewEnd=0;
    let started=false, hideUITimer=null;

    let remoteDescriptionSet=false; const candidateQueue=[];
    let needOfferTimer=null; let lastOfferSdp=null;

    // camera/front-state
    let isFront = false;

    // Pose inference state (sender side)
    let PoseLandmarker=null, FilesetResolver=null, DrawingUtils=null, drawingUtils=null, poseTask=null;
    let poseLoopRunning=false, lastVideoTime=-1;

    // UI flags → logic
    const poseState = {
      enabled: false,
      where: 'sender',   // 'sender' | 'receiver'
    };

    /* ================== Helpers ================== */
    const logS = (...a) => console.log('[SENDER]', ...a);
    const logP = (...a) => console.log('[POSE][sender]', ...a);
    const setStatus = (t) => { statusEl.textContent = t; console.log('[STATUS]', t); };

    function currentRoom() {
      const r = (roomInput.value || 'Baby').trim();
      try { const u = new URL(location.href); u.searchParams.set('room', r); history.replaceState({}, '', u); } catch {}
      return r;
    }

    async function requestWakeLock() {
      try {
        if ('wakeLock' in navigator) {
          wakeLock = await navigator.wakeLock.request('screen');
          document.addEventListener('visibilitychange', async () => {
            if (document.visibilityState === 'visible') {
              try { wakeLock = await navigator.wakeLock.request('screen'); } catch {}
            }
          });
        }
      } catch {}
    }

    function isOverlayVisibleOnSender(){
      return document.body.classList.contains('previewing') || document.body.classList.contains('ui-visible');
    }

    /* ===== Fit overlay canvas to letterboxed local video ===== */
    function sizeCanvasToLocalVideoRect(){
      const bodyRect = document.body.getBoundingClientRect();
      const cw = bodyRect.width, ch = bodyRect.height;                // CSS px
      const vw = localVideo.videoWidth  || 1280;
      const vh = localVideo.videoHeight || 720;
      const scale = Math.min(cw / vw, ch / vh);
      const rw = vw * scale, rh = vh * scale;
      const ox = (cw - rw) / 2, oy = (ch - rh) / 2;

      // CSS size/pos to match visible video
      poseCanvas.style.left = ox + 'px';
      poseCanvas.style.top  = oy + 'px';
      poseCanvas.style.width  = rw + 'px';
      poseCanvas.style.height = rh + 'px';

      // Backing store (device pixels)
      const dpr = window.devicePixelRatio || 1;
      poseCanvas.width  = Math.max(1, Math.round(rw * dpr));
      poseCanvas.height = Math.max(1, Math.round(rh * dpr));

      // Mirror canvas exactly as video (for front camera)
      const t = isFront ? 'scaleX(-1)' : 'none';
      poseCanvas.style.transform = t;
      localVideo.style.transform = t;

      // clear
      poseCtx.setTransform(1,0,0,1,0,0);
      poseCtx.clearRect(0,0,poseCanvas.width, poseCanvas.height);
    }
    window.addEventListener('resize', sizeCanvasToLocalVideoRect);
    localVideo.addEventListener('loadedmetadata', sizeCanvasToLocalVideoRect);
    localVideo.addEventListener('resize', sizeCanvasToLocalVideoRect);

    /* ================== Media capture ================== */
    function applyVideoToggle() {
      if (!localStream) return;
      const vt = localStream.getVideoTracks()[0];
      if (vt) {
        vt.enabled = videoOn.checked;
        setStatus(videoOn.checked ? 'Video ON' : 'Video OFF');
        if (document.body.classList.contains('previewing')) {
          localVideo.style.display = videoOn.checked ? 'block' : 'none';
          poseCanvas.style.display = (videoOn.checked && isOverlayVisibleOnSender()) ? 'block' : 'none';
        }
      } else if (started && videoOn.checked) {
        setStatus('Video not captured. Stop & Start to enable video.');
      }
    }
    function applyAudioToggle() {
      if (!localStream) return;
      const at = localStream.getAudioTracks()[0];
      if (at) {
        at.enabled = audioOn.checked;
        setStatus(audioOn.checked ? 'Audio ON' : 'Audio OFF');
      } else if (started && audioOn.checked) {
        setStatus('Audio not captured. Stop & Start to enable audio.');
      }
    }
    videoOn.addEventListener('change', applyVideoToggle);
    audioOn.addEventListener('change', applyAudioToggle);

    async function getMedia() {
      const wantVideo = videoOn.checked;
      const wantAudio = audioOn.checked;
      if (!wantVideo && !wantAudio) throw new Error('Both video and audio are OFF.');

      const facing = cameraSel.value || 'environment';
      isFront = (facing === 'user');

      const constraints = {
        video: wantVideo ? {
          facingMode: facing,
          width: { ideal: 1280 }, height: { ideal: 720 },
          frameRate: { ideal: 30, max: 30 }
        } : false,
        audio: wantAudio ? { echoCancellation: true, noiseSuppression: true, autoGainControl: true } : false
      };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      const vt = stream.getVideoTracks()[0]; if (vt) vt.enabled = wantVideo;
      const at = stream.getAudioTracks()[0]; if (at) at.enabled = wantAudio;
      if (vt && 'contentHint' in vt) { try { vt.contentHint = 'motion'; } catch {} }

      return stream;
    }

    /* ================== Signaling ================== */
    function connectWS(room) {
      return new Promise((resolve, reject) => {
        const url = `${WS_ENDPOINT}?room=${encodeURIComponent(room)}`;
        setStatus('Connecting to signaling…');
        ws = new WebSocket(url);

        let opened = false;
        const timer = setTimeout(() => {
          if (!opened) { try { ws.close(); } catch{}; setStatus('Signaling: timeout'); reject(new Error('WS timeout')); }
        }, 15000);

        ws.onopen = () => {
          opened = true; clearTimeout(timer);
          setStatus('Signaling: connected');
          send({ type: 'join', room });
          send({ type: 'hello', who: 'sender' });
          // Ask for offers until we get one
          send({ type: 'need-offer' });
          needOfferTimer = setInterval(() => {
            if (!remoteDescriptionSet) {
              console.log('[WS OUT] need-offer (retry)');
              send({ type: 'need-offer' });
            } else {
              clearInterval(needOfferTimer); needOfferTimer = null;
            }
          }, NEED_OFFER_INTERVAL_MS);
          resolve();
        };
        ws.onmessage = onSignal;
        ws.onerror = (e) => { console.error('[WS error]', e); setStatus('Signaling: error'); };
        ws.onclose = (e) => { console.warn('[WS closed]', e.code, e.reason); setStatus('Signaling: closed'); };
      });
    }
    const send = (obj) => { try { if (ws && ws.readyState === WebSocket.OPEN) ws.send(JSON.stringify(obj)); } catch {} };

    function createPC() {
      pc = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
        bundlePolicy: 'max-bundle',
        sdpSemantics: 'unified-plan'
      });
      pc.onicecandidate = (e) => { if (e.candidate) send({ type: 'candidate', candidate: e.candidate }); };
      pc.oniceconnectionstatechange = () => setStatus('ICE: ' + pc.iceConnectionState);

      // Add media tracks
      localStream.getTracks().forEach(track => pc.addTrack(track, localStream));

      // Create a single bidirectional data channel for pose
      poseDC = pc.createDataChannel('pose');
      poseDC.onopen = () => logP('datachannel open');
      poseDC.onclose = () => logP('datachannel close');
      poseDC.onerror = (e) => console.warn('[POSE][sender] DC error', e);
      poseDC.onmessage = (ev) => {
        // Landmarks coming from receiver (when receiver runs inference):
        try {
          const m = JSON.parse(ev.data);
          if (m.t === 'pose' && Array.isArray(m.pts)) {
            // Draw on sender only if overlay visible and Pose enabled (receiver-side mode)
            if (poseState.enabled && poseState.where === 'receiver' && isOverlayVisibleOnSender()) {
              drawPoseOnSender(m.pts);
            }
          }
        } catch {}
      };
    }

    async function onSignal(evt) {
      let msg; try { msg = JSON.parse(evt.data); } catch { return; }
      // console.log('[WS IN]', msg.type);

      if (msg.type === 'offer') {
        setStatus('Got offer, creating answer…');
        if (!pc) createPC();

        if (pc.signalingState === 'have-local-offer') {
          try { await pc.setLocalDescription({ type: 'rollback' }); } catch {}
        }

        if (lastOfferSdp === msg.sdp) {
          console.log('[DUP] identical offer ignored');
          return;
        }
        lastOfferSdp = msg.sdp;

        await pc.setRemoteDescription(new RTCSessionDescription(msg));
        remoteDescriptionSet = true;

        while (candidateQueue.length) {
          const c = candidateQueue.shift();
          try { await pc.addIceCandidate(c); } catch (err) { console.warn('late ICE add failed', err); }
        }

        const answer = await pc.createAnswer();
        await pc.setLocalDescription(answer);
        send(answer);

        // Re-announce current inference mode to the receiver
        announcePoseMode();

      } else if (msg.type === 'candidate' && msg.candidate) {
        const cand = new RTCIceCandidate(msg.candidate);
        if (remoteDescriptionSet && pc) {
          try { await pc.addIceCandidate(cand); } catch (err) { console.warn('ICE add failed', err); }
        } else {
          candidateQueue.push(cand);
        }
      } else if (msg.type === 'peer-joined') {
        // new receiver → tell it our current mode
        announcePoseMode();
      }
    }

    /* ================== Pose (sender) ================== */
    async function ensureSenderDrawing(){
      if (drawingUtils) return;
      const mod = await import('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0');
      DrawingUtils = mod.DrawingUtils; PoseLandmarker = mod.PoseLandmarker; FilesetResolver = mod.FilesetResolver;
      drawingUtils = new DrawingUtils(poseCtx);
      logP('DrawingUtils loaded');
    }
    async function ensureSenderPoseTask(){
      if (poseTask) return;
      await ensureSenderDrawing();
      try {
        const vision = await FilesetResolver.forVisionTasks('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm');
        poseTask = await PoseLandmarker.createFromOptions(vision, {
          baseOptions:{ modelAssetPath:'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task', delegate:'GPU' },
          runningMode:'VIDEO', numPoses:1
        });
      } catch (gpuErr) {
        console.warn('[POSE][sender] GPU failed, fallback CPU:', gpuErr);
        const vision = await FilesetResolver.forVisionTasks('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm');
        poseTask = await PoseLandmarker.createFromOptions(vision, {
          baseOptions:{ modelAssetPath:'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task', delegate:'CPU' },
          runningMode:'VIDEO', numPoses:1
        });
      }
    }

    function clearSenderOverlay(){
      poseCtx.setTransform(1,0,0,1,0,0);
      poseCtx.clearRect(0,0,poseCanvas.width, poseCanvas.height);
    }

    function drawPoseOnSender(pts){
      // pts are normalized [0..1] coords; our canvas already sized to visible rect and mirrored via CSS if front
      if (!drawingUtils) return;
      clearSenderOverlay();
      const lms = pts.map(p => ({ x: p[0], y: p[1] }));
      drawingUtils.drawLandmarks(lms, { radius: () => 4 * (window.devicePixelRatio || 1) });
      drawingUtils.drawConnectors(lms, PoseLandmarker.POSE_CONNECTIONS, { lineWidth: 2 });
    }

    function sendPoseToPeer(pts){
      if (!poseDC || poseDC.readyState !== 'open') return;
      try { poseDC.send(JSON.stringify({ t:'pose', pts })); } catch {}
    }

    async function startSenderPoseLoop(){
      if (poseLoopRunning) return;
      await ensureSenderPoseTask();  // task + drawing
      poseLoopRunning = true; lastVideoTime = -1;
      logP('inference START (sender)');
      requestAnimationFrame(poseLoop);
    }
    function stopSenderPoseLoop(){
      poseLoopRunning = false;
      logP('inference STOP (sender)');
      clearSenderOverlay();
    }

    function poseLoop(){
      if (!poseLoopRunning) return;
      if (!localVideo.videoWidth || !localVideo.videoHeight) { requestAnimationFrame(poseLoop); return; }

      const now = performance.now();
      if (lastVideoTime === localVideo.currentTime) { requestAnimationFrame(poseLoop); return; }
      lastVideoTime = localVideo.currentTime;

      try {
        const res = poseTask.detectForVideo(localVideo, now);
        const arr = (res.landmarks && res.landmarks[0]) ? res.landmarks[0].map(l => [l.x, l.y]) : [];
        // Draw locally if visible
        if (poseState.enabled && poseState.where === 'sender' && isOverlayVisibleOnSender() && arr.length) {
          drawPoseOnSender(arr);
        } else {
          clearSenderOverlay();
        }
        // Always send to peer in sender-mode
        if (poseState.enabled && poseState.where === 'sender' && arr.length) {
          sendPoseToPeer(arr);
        }
      } catch (e) { /* keep going */ }

      requestAnimationFrame(poseLoop);
    }

    // Broadcast our current pose mode to the receiver
    function announcePoseMode(){
      const mode = (!poseState.enabled) ? 'off' : (poseState.where === 'sender' ? 'sender' : 'receiver');
      logP('announce inference-mode:', mode);
      send({ type:'inference-mode', task:'pose', mode });
    }

    // React to UI changes for Pose
    function applyPoseUI(){
      poseState.enabled = cbPose.checked;
      poseState.where = selPose.value; // 'sender' | 'receiver'
      // enable/disable dropdown
      selPose.disabled = !poseState.enabled;

      logP('UI → enabled:', poseState.enabled, '| where:', poseState.where);

      if (!started) {
        // Not streaming: only update mode announcement later on connect
        clearSenderOverlay();
        return;
      }

      if (!poseState.enabled) {
        // stop all local compute & drawing; notify receiver to stop
        stopSenderPoseLoop();
        announcePoseMode();
        return;
      }

      if (poseState.where === 'sender') {
        // run here, draw here (when visible) and send to receiver for drawing
        startSenderPoseLoop();
        announcePoseMode();
      } else {
        // run on receiver: stop local compute, we will draw ONLY on sender from DC-incoming points
        stopSenderPoseLoop();
        announcePoseMode();
        // No local drawing until DC messages arrive
        clearSenderOverlay();
      }
    }
    cbPose.addEventListener('change', applyPoseUI);
    selPose.addEventListener('change', applyPoseUI);

    /* ================== Preview + UI flow ================== */
    function beginPreviewWindow(minutes) {
      const ms = Math.max(0, Math.round((Number(minutes) || 1) * 60000));
      if (ms === 0) { enterBlackout(); return; }

      document.body.classList.add('previewing');
      document.body.classList.add('streaming');
      document.body.classList.remove('ui-visible');
      ui.style.display = '';
      localVideo.style.display = videoOn.checked ? 'block' : 'none';
      poseCanvas.style.display = (videoOn.checked ? 'block' : 'none');

      previewEnd = Date.now() + ms;
      tickPreviewCountdown();
      previewTicker = setInterval(tickPreviewCountdown, 1000);
      previewTimer  = setTimeout(endPreviewNow, ms);
    }
    function tickPreviewCountdown() {
      const remain = Math.max(0, previewEnd - Date.now());
      const sec = Math.ceil(remain / 1000);
      const mm = String(Math.floor(sec / 60)).padStart(2,'0');
      const ss = String(sec % 60).padStart(2,'0');
      setStatus(`Preview ends in ${mm}:${ss}`);
    }
    function endPreviewNow() {
      if (previewTimer) clearTimeout(previewTimer);
      if (previewTicker) clearInterval(previewTicker);
      previewTimer = previewTicker = null;
      enterBlackout();
    }
    function enterBlackout() {
      document.body.classList.remove('previewing');
      document.body.classList.add('streaming');
      document.body.classList.remove('ui-visible');
      localVideo.style.display = 'none';
      poseCanvas.style.display = 'none';
      setStatus('Streaming...');
      clearTimeout(hideUITimer); hideUITimer = null;
    }

    async function startOrStop() {
      try {
        if (started) { await stopStreaming(); return; }

        startBtn.disabled = true;
        const room = currentRoom();

        setStatus('Starting camera…');
        localStream = await getMedia();
        localVideo.srcObject = localStream;
        sizeCanvasToLocalVideoRect();

        applyVideoToggle();
        applyAudioToggle();

        beginPreviewWindow(Number(previewMinsInput.value) || 1);

        await connectWS(room);
        await requestWakeLock();

        started = true;
        startBtn.textContent = 'Stop streaming';
        startBtn.disabled = false;

        // Apply current Pose UI after start (may start loops / announce mode)
        applyPoseUI();

      } catch (err) {
        console.error(err);
        alert(err.message || err);
        setStatus('Idle');
        startBtn.disabled = false;
      }
    }

    async function stopStreaming() {
      try { send({ type: 'bye' }); } catch {}

      if (previewTimer) clearTimeout(previewTimer);
      if (previewTicker) clearInterval(previewTicker);
      if (hideUITimer) clearTimeout(hideUITimer);
      if (needOfferTimer) clearInterval(needOfferTimer);
      previewTimer = previewTicker = hideUITimer = needOfferTimer = null;

      // Stop pose loop
      stopSenderPoseLoop();

      try { pc && pc.getSenders().forEach(s => s.track && s.track.stop()); } catch {}
      try { localStream && localStream.getTracks().forEach(t => t.stop()); } catch {}
      try { pc && pc.close(); } catch {}
      try { ws && ws.close(); } catch {}

      localStream = null; pc = null; ws = null; poseDC = null;
      started = false;

      remoteDescriptionSet = false;
      candidateQueue.length = 0;
      lastOfferSdp = null;

      document.body.classList.remove('previewing','streaming','ui-visible');
      document.body.classList.add('blackout');
      ui.style.display = '';
      localVideo.style.display = 'none';
      poseCanvas.style.display = 'none';
      clearSenderOverlay();
      setStatus('Stopped');

      startBtn.textContent = 'Start streaming';
    }

    // UI show/hide while streaming
    document.addEventListener('click', (e) => {
      if (document.body.classList.contains('previewing')) {
        endPreviewNow(); return;
      }
      if (document.body.classList.contains('streaming') && !document.body.classList.contains('ui-visible')) {
        document.body.classList.add('ui-visible'); setStatus('Streaming...'); scheduleAutoHideUI(); return;
      }
      if (document.body.classList.contains('streaming') && document.body.classList.contains('ui-visible')) {
        const inCard = e.target.closest('.card');
        if (!inCard) { document.body.classList.remove('ui-visible'); setStatus('Streaming...'); clearTimeout(hideUITimer); hideUITimer = null; }
      }
    });
    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape') {
        if (document.body.classList.contains('previewing')) { endPreviewNow(); }
        else if (document.body.classList.contains('streaming') && document.body.classList.contains('ui-visible')) {
          document.body.classList.remove('ui-visible'); setStatus('Streaming...'); clearTimeout(hideUITimer); hideUITimer = null;
        }
      }
    });
    function scheduleAutoHideUI() {
      clearTimeout(hideUITimer);
      hideUITimer = setTimeout(() => {
        if (document.body.classList.contains('streaming')) {
          document.body.classList.remove('ui-visible');
          setStatus('Streaming...');
        }
      }, UI_AUTOHIDE_MS);
    }
    function resetAutoHideUI() {
      if (document.body.classList.contains('streaming') && document.body.classList.contains('ui-visible')) {
        scheduleAutoHideUI();
      }
    }
    document.addEventListener('mousemove', resetAutoHideUI, { passive: true });
    document.addEventListener('touchstart', resetAutoHideUI, { passive: true });

    window.addEventListener('beforeunload', stopStreaming);
    startBtn.addEventListener('click', startOrStop);

    // Camera change re-gets media when not streaming; when streaming, ask user to stop/start
    cameraSel.addEventListener('change', () => {
      if (!started) return;
      alert('Change camera requires Stop streaming, then Start again.');
    });
  </script>
</body>
</html>
