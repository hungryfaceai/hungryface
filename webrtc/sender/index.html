<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Baby Monitor – Sender</title>
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"/>
  <style>
    :root { color-scheme: dark; }
    html, body {
      margin: 0; height: 100%;
      background: #000; color: #ccc; font-family: -apple-system, system-ui, Segoe UI, Roboto, sans-serif;
      touch-action: manipulation;
    }

    /* Stage explicitly sized to the *visible* viewport on iOS */
    #stage {
      position: fixed; inset: 0; z-index: 1;
      width: 100vw; height: 100vh;     /* fallback */
      width: 100dvw; height: 100dvh;   /* dynamic viewport (iOS 16+) */
      width: 100svw; height: 100svh;   /* small viewport (iOS URL bar safe) */
    }

    /* Letterboxed preview (no crop) */
    #stage > video#local {
      position: absolute; inset: 0; width: 100%; height: 100%;
      object-fit: contain; background: #000; display: none; pointer-events: none;
    }

    /* Canvas positioned by JS to cover the visible video box */
    #stage > canvas#poseCanvas {
      position: absolute; /* left/top/width/height set in JS */
      display: none; background: transparent; pointer-events: none;
    }

    /* Visual mirror for preview when using front camera */
    .mirror #local, .mirror #poseCanvas { transform: scaleX(-1); }

    #ui {
      position: relative; z-index: 5; min-height: 100svh;
      display: flex; align-items: center; justify-content: center; padding: 20px;
    }

    @media (max-height: 820px) {
      #ui { align-items: flex-start; padding-top: 0; }
      .page-header { padding: 2px 10px; }
    }

    @media (max-height: 660px) {
      .page-header { padding: 2px 10px; }
      .icon-home   { --icon-size: 26px; }
    }

    /* Kill first-heading top margin + keep tight line-height */
    .page-header h1,
    .page-header h2,
    #ui > h1:first-child,
    #ui > h2:first-child {
      margin-top: 0;
      line-height: 1.15;
    }
    
    /* Header hugs the notch; only real safe-area padding remains */
    .page-header {
      padding-top: max(env(safe-area-inset-top), 2px);
      padding-bottom: 4px;
    }
    
    /* Use visible viewport height to avoid iOS toolbar gap */
    #ui { min-height: 100svh; }
    
    /* On short screens, keep header tight; no extra top padding */
    @media (max-height: 740px) {
      #ui { padding-top: 0; }
      .page-header { padding: 2px 10px; }
    }

    
    .card {
      width: 100%; max-width: 520px; background: #0b0b0b; border: 1px solid #141414; border-radius: 14px;
      padding: 18px; box-sizing: border-box;
    }

    .card h2 { font-size: clamp(16px, 2.6vw, 18px); }

    .row { display: flex; align-items: center; justify-content: space-between; gap: 12px; margin: 10px 0; }
    label.switch { display: flex; align-items: center; gap: 10px; font-size: 16px; }
    input[type="checkbox"] { width: 22px; height: 22px; }
    input[type="text"], select, input[type="number"] {
      width: 100%; padding: 10px 12px; border-radius: 10px; border: 1px solid #222; background:#0b0b0b; color:#ddd;
      -moz-appearance:textfield;
    }
    #cameraSel { font-size: 18px; padding: 14px 16px; height: 52px; border-radius: 12px; }
    input[type="number"]::-webkit-outer-spin-button,
    input[type="number"]::-webkit-inner-spin-button { -webkit-appearance: none; margin: 0; }
    button {
      width: 100%; padding: 14px 16px; border-radius: 12px; border: 0;
      background: #2a2a2a; color: #fff; font-size: 17px; font-weight: 600;
      cursor: pointer;
    }
    button:active { transform: scale(0.99); }

    .overlay {
      position: fixed; inset: 0; display: none; align-items: center; justify-content: center;
      pointer-events: none; z-index: 4;
    }
    body.streaming .overlay, body.previewing .overlay { display: flex; }
    .status {
      background: rgba(255,255,255,0.05); border: 1px solid rgba(255,255,255,0.1);
      color: #ddd; font-size: 14px; padding: 10px 14px; border-radius: 12px;
      text-align: center; white-space: pre-line; max-width: 90vw;
    }

    #tap { position: fixed; inset: 0; display: none; z-index: 6; }
    body.streaming:not(.ui-visible) #tap { display: block; }
    body.streaming:not(.ui-visible) #ui { display: none; }
    body.blackout { background: #000; }

    fieldset.ai { border: 1px solid #222; border-radius: 12px; padding: 10px 12px; }
    fieldset.ai legend { padding: 0 6px; color: #bbb; }
    .ai-row { display: grid; grid-template-columns: 1fr 140px; gap: 8px; align-items: center; margin: 10px 0; }
    .ai-row select { width: 100%; padding: 8px 10px; border-radius: 10px; border: 1px solid #222; background:#0b0b0b; color:#ddd; }
  </style>
</head>
<body class="blackout">

  <!-- Header -->
  <header class="page-header">
    <a href="https://hungryfaceai.github.io/hungryface/home/" class="home-link" aria-label="Home">
      <svg class="icon icon-home" aria-hidden="true" focusable="false">
        <use href="/hungryface/assets/icons.svg#icon-cradle-ai"
             xlink:href="/hungryface/assets/icons.svg#icon-cradle-ai"></use>
      </svg>
    </a>
  </header>
  
  <style>
    .page-header {
      position: relative;
      z-index: 7;          /* above #stage (z:1), #ui (z:5) and #tap (z:6), so it stays clickable */
      padding: 14px 20px;  /* matches landing header spacing */
    }

    .home-link {
      position: static;     /* was: fixed */
      /*top: 14px;               aligns with home page header padding
      left: 20px;
      z-index: 9999;*/
  
      /* Typography and color to match the home page */
      font-family: -apple-system, system-ui, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
      font-size: 0.95rem;     /* same as header nav */
      color: #fff;
      text-decoration: none;
      opacity: 0.9;

    /* Remove pill/background/border so it matches the plain header link */
    background: transparent;
    border: none;
    padding: 0;
  }
  .home-link:hover,
  .home-link:focus {
    text-decoration: underline;
    opacity: 1;
  }

  /* iPhone 12 mini (~360px): smaller nav text, same as home page tweak */
  @media (max-width: 380px) {
    .home-link { font-size: 0.82rem; }
  }
    
  .icon { width: var(--icon-size, 24px); height: var(--icon-size, 24px); display: block; }
  .icon-home { --icon-size: 26px; } /* same size as landing page */    
</style>

  <div id="stage">
    <video id="local" playsinline autoplay muted></video>
    <canvas id="poseCanvas"></canvas>
  </div>

  <div id="ui">
    <div class="card">
      <h2 style="margin:0 0 8px 0;">Camera (Baby)</h2>

      <div class="row">
        <label class="switch">
          <input id="videoOn" type="checkbox" checked><span>Video ON</span>
        </label>
        <label class="switch">
          <input id="audioOn" type="checkbox" checked><span>Audio ON</span>
        </label>
      </div>

      <div class="row">
        <select id="cameraSel" aria-label="Camera">
          <option value="environment" selected>Back camera</option>
          <option value="user">Front camera</option>
        </select>
      </div>

      <div class="row">
        <input id="room" type="text" placeholder="Room (e.g., Baby)" value="Baby" autocomplete="off">
        <span style="opacity:.7;font-size:13px;">Room name</span>
      </div>

      <div class="row">
        <input id="previewMins" type="number" min="0" step="1" value="1" aria-label="Preview minutes">
        <span style="opacity:.7;font-size:13px;">Preview minutes</span>
      </div>

      <fieldset class="ai">
        <legend>AI features</legend>
        <div class="ai-row">
          <label class="switch">
            <input id="poseOn" type="checkbox"><span>Pose</span>
          </label>
          <select id="poseWhere">
            <option value="sender" selected>On sender</option>
            <option value="receiver">On receiver</option>
          </select>
        </div>
        
        <div class="ai-row">
          <label class="switch">
            <input id="audioAiOn" type="checkbox"><span>Audio</span>
          </label>
          <select id="audioAiWhere">
            <option value="sender" selected>On sender</option>
            <option value="receiver">On receiver</option>
          </select>
        </div>
        
        <div class="ai-row">
          <label class="switch">
            <input id="faceOn" type="checkbox"><span>Face</span>
          </label>
          <select id="faceWhere">
            <option value="sender" selected>On sender</option>
            <option value="receiver">On receiver</option>
          </select>
        </div>

      </fieldset>

      <div class="row" style="margin-top:14px;">
        <button id="startBtn">Start streaming</button>
      </div>
    </div>
  </div>

  <div id="tap" aria-hidden="true"></div>
  <div class="overlay"><div class="status" id="status">Idle</div></div>

  <script type="module">
    const WS_ENDPOINT = "wss://signaling-server-f5gu.onrender.com/ws";
    const UI_AUTOHIDE_MS = 10000;
    //const NEED_OFFER_INTERVAL_MS = 3000; //now unused https://chatgpt.com/c/68a874e7-225c-832b-b147-60cfea788ffb
    const TASKS_URL  = "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";
    const WASM_DIR   = TASKS_URL + "/wasm";
    const AUDIO_TASKS_URL = "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-audio@0.10.0";
    const AUDIO_WASM_DIR  = AUDIO_TASKS_URL + "/wasm";

    const roomInput = document.getElementById('room');
    const videoOn   = document.getElementById('videoOn');
    const audioOn   = document.getElementById('audioOn');
    const cameraSel = document.getElementById('cameraSel');
    const previewMinsInput = document.getElementById('previewMins');
    const startBtn  = document.getElementById('startBtn');
    const localVideo= document.getElementById('local');
    const poseCanvas= document.getElementById('poseCanvas');
    const statusEl  = document.getElementById('status');
    const ui        = document.getElementById('ui');
    const tap       = document.getElementById('tap');
    const stage     = document.getElementById('stage');

    const poseOn    = document.getElementById('poseOn');
    const poseWhere = document.getElementById('poseWhere');
    const audioAiOn    = document.getElementById('audioAiOn');
    const audioAiWhere = document.getElementById('audioAiWhere');
    const faceOn       = document.getElementById('faceOn');
    const faceWhere    = document.getElementById('faceWhere');    

    function announceAIModes() {
      // 1) Apply local behavior + per-feature mode messages (pose/audio/face)
      applyPoseUI();
      applyAudioUI();
      applyFaceUI();
    
      // 2) Broadcast one consolidated snapshot
      const payload = {
        type: 'ai-modes',
        pose:  { enabled: !!poseOn.checked,        where: poseWhere.value },
        audio: { enabled: !!audioAiOn?.checked,    where: audioAiWhere?.value },
        face:  { enabled: !!faceOn?.checked,       where: faceWhere?.value }
      };
      for (const ch of poseDCs) if (ch.readyState === 'open') {
        ch.send(JSON.stringify(payload));
      }
    }

    // One compact block for ALL AI controls (pose + audio + face)
    [poseOn, poseWhere, audioAiOn, audioAiWhere, faceOn, faceWhere]
      .filter(Boolean)
      .forEach(el => el.addEventListener('change', announceAIModes));


    /* -----------------------
       PERSISTENCE (localStorage) — no behavior changes
       ----------------------- */
    (function () {
      const PREFIX = 'bm_sender_';

      // Map of controls to persist
      const entries = [
        ['videoOn',    'checkbox', document.getElementById('videoOn')],
        ['audioOn',    'checkbox', document.getElementById('audioOn')],
        ['cameraSel',  'select',   document.getElementById('cameraSel')],
        ['room',       'text',     document.getElementById('room')],
        ['previewMins','number',   document.getElementById('previewMins')],
        ['poseOn',     'checkbox', document.getElementById('poseOn')],
        ['poseWhere',    'select',   poseWhere],
    
        // NEW: persist Audio + Face AI exactly the same way
        ['audioAiOn',    'checkbox', audioAiOn],
        ['audioAiWhere', 'select',   audioAiWhere],
        ['faceOn',       'checkbox', faceOn],
        ['faceWhere',    'select',   faceWhere],
      ].filter(([, , el]) => !!el); // keep only those that exist

      // Also persist the (currently disabled) Audio/Face AI controls and their dropdowns.
      // We don't add IDs or change markup; we select by structure:
      /*const aiRows = document.querySelectorAll('fieldset.ai .ai-row');
      const audioRow = aiRows[1], faceRow = aiRows[2];
      const audioChk = audioRow?.querySelector('input[type="checkbox"]');
      const audioSel = audioRow?.querySelector('select');
      const faceChk  = faceRow?.querySelector('input[type="checkbox"]');
      const faceSel  = faceRow?.querySelector('select');
      if (audioChk) entries.push(['audioAiOn',   'checkbox', audioChk]);
      if (audioSel) entries.push(['audioAiWhere','select',   audioSel]);
      if (faceChk)  entries.push(['faceOn',      'checkbox', faceChk]);
      if (faceSel)  entries.push(['faceWhere',   'select',   faceSel]);*/

      function loadOne(key, type, el) {
        if (!el) return;
        const v = localStorage.getItem(PREFIX + key);
        if (v == null) return; // leave current default if nothing saved
        if (type === 'checkbox') el.checked = (v === '1' || v === 'true');
        else el.value = v;
      }

      function saveOne(key, type, el) {
        if (!el) return;
        const v = (type === 'checkbox') ? (el.checked ? '1' : '0') : el.value;
        try { localStorage.setItem(PREFIX + key, v); } catch {}
      }

      // Apply saved values (does NOT dispatch events, so no behavior changes)
      entries.forEach(([k, t, el]) => loadOne(k, t, el));

      // Save on change
      entries.forEach(([k, t, el]) => el && el.addEventListener('change', () => saveOne(k, t, el)));

      // If a ?room= is present, persist that value too (existing code still sets the input)
      const qsRoomVal = new URLSearchParams(location.search).get('room');
      if (qsRoomVal) { try { localStorage.setItem(PREFIX + 'room', qsRoomVal); } catch {} }
    })();

    /* bm - 22 aug 2025 - 16:43
    let ws = null, pc = null, localStream = null;
    let started = false, hideUITimer = null;

    let remoteDescriptionSet = false;
    const candidateQueue = [];
    let needOfferTimer = null, lastOfferSdp = null;
    */
    let ws = null, localStream = null;
    let started = false, hideUITimer = null;
    
    // One RTCPeerConnection per receiver
    // peers: Map<peerId, { pc, remoteDescriptionSet: boolean, candidateQueue: RTCIceCandidate[], lastOfferSdp: string|null }>
    const peers = new Map();
    
    // Optional: if you keep the preview/pose logic as-is
    let needOfferTimer = null; // (we won't use the interval anymore)
    //end bm - 22 aug 2025 - 16:43

    let previewTimer = null, previewTicker = null, previewEnd = 0;
    const poseDCs = new Set();

    let PoseLandmarker, FilesetResolver, DrawingUtils;
    let poseTask = null, poseLoopRunning = false;

    let FaceLandmarker, faceTask = null, faceLoopRunning = false;
    let AudioClassifier, audioTask = null, audioLoopRunning = false;
    let AudioFilesetResolver; // alias to avoid clashing with vision FilesetResolver
    
    const ctx = poseCanvas.getContext('2d', { alpha: true });

    const setStatus = (t) => { statusEl.textContent = t; console.log('[STATUS]', t); };
    const currentRoom = () => (roomInput.value || 'Baby').trim();
    const isFront = () => (cameraSel.value === 'user');

    function updateMirrorClass() {
      document.body.classList.toggle('mirror', isFront());
    }

    /* ----- Canvas alignment (letterbox-aware inside #stage) ----- */
    function resizeCanvasToVideo() {
      const showVideo = document.body.classList.contains('previewing') && videoOn.checked;
      localVideo.style.display = showVideo ? 'block' : 'none';

      const stageBox = stage.getBoundingClientRect();
      const containerW = Math.round(stageBox.width);
      const containerH = Math.round(stageBox.height);
      const vidW = localVideo.videoWidth  || 1;
      const vidH = localVideo.videoHeight || 1;

      const scale = Math.min(containerW / vidW, containerH / vidH);
      const fitW = Math.round(vidW * scale);
      const fitH = Math.round(vidH * scale);
      const fitLeft = Math.floor((containerW - fitW) / 2);
      const fitTop  = Math.floor((containerH - fitH) / 2);

      poseCanvas.style.left   = fitLeft + 'px';
      poseCanvas.style.top    = fitTop  + 'px';
      poseCanvas.style.width  = fitW + 'px';
      poseCanvas.style.height = fitH + 'px';

      const dpr = window.devicePixelRatio || 1;
      const needW = Math.max(1, Math.round(fitW * dpr));
      const needH = Math.max(1, Math.round(fitH * dpr));
      if (poseCanvas.width !== needW || poseCanvas.height !== needH) {
        poseCanvas.width  = needW;
        poseCanvas.height = needH;
      }

      poseCanvas.style.display =
        (poseOn.checked && videoOn.checked && document.body.classList.contains('previewing'))
          ? 'block' : 'none';

      ctx.setTransform(1,0,0,1,0,0);
    }

    // Post-change settle loop (iOS toolbars/orientation)
    let settleRAF = 0, settleUntil = 0;
    function beginViewportSettle(durationMs = 1200) {
      settleUntil = performance.now() + durationMs;
      if (settleRAF) return;
      const tick = () => {
        resizeCanvasToVideo();
        if (performance.now() < settleUntil) {
          settleRAF = requestAnimationFrame(tick);
        } else {
          cancelAnimationFrame(settleRAF); settleRAF = 0;
          resizeCanvasToVideo();
        }
      };
      tick();
    }

    localVideo.addEventListener('loadedmetadata', () => {
      console.log('[MEDIA] local video meta', localVideo.videoWidth, 'x', localVideo.videoHeight);
      beginViewportSettle();
    });
    localVideo.addEventListener('resize', beginViewportSettle);

    const vpAlign = () => beginViewportSettle();
    ['resize','orientationchange','scroll'].forEach(ev =>
      window.addEventListener(ev, vpAlign, { passive: true })
    );
    if (window.visualViewport) {
      window.visualViewport.addEventListener('resize', vpAlign, { passive: true });
      window.visualViewport.addEventListener('scroll',  vpAlign, { passive: true });
    }
    document.addEventListener('visibilitychange', () => {
      if (!document.hidden) beginViewportSettle();
    });

    async function getMedia() {
      const wantVideo = videoOn.checked;
      const wantAudio = audioOn.checked;
      if (!wantVideo && !wantAudio) throw new Error('Both video and audio are OFF.');

      const constraints = {
        video: wantVideo ? {
          facingMode: cameraSel.value || 'environment',
          width: { ideal: 1280 }, height: { ideal: 720 },
          frameRate: { ideal: 30, max: 30 }
        } : false,
        audio: wantAudio ? { echoCancellation: true, noiseSuppression: true, autoGainControl: true } : false
      };
      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      const vt = stream.getVideoTracks()[0];
      const at = stream.getAudioTracks()[0];
      if (vt && 'contentHint' in vt) { try { vt.contentHint = 'motion'; } catch {} }
      if (vt) vt.enabled = wantVideo;
      if (at) at.enabled = wantAudio;
      return stream;
    }

    function applyVideoToggle() {
      if (!localStream) return;
      const vt = localStream.getVideoTracks()[0];
      if (vt) vt.enabled = videoOn.checked;
      beginViewportSettle();
      setStatus(videoOn.checked ? 'Video ON' : 'Video OFF');
    }
    function applyAudioToggle() {
      if (!localStream) return;
      const at = localStream.getAudioTracks()[0];
      if (at) at.enabled = audioOn.checked;
      setStatus(audioOn.checked ? 'Audio ON' : 'Audio OFF');
    }
    videoOn.addEventListener('change', applyVideoToggle);
    audioOn.addEventListener('change', applyAudioToggle);
    cameraSel.addEventListener('change', () => { updateMirrorClass(); beginViewportSettle(); });

    function connectWS(room) {
      return new Promise((resolve, reject) => {
        const url = `${WS_ENDPOINT}?room=${encodeURIComponent(room)}`;
        setStatus('Connecting to signaling…');
        const sock = new WebSocket(url);
        ws = sock;

        let opened = false;
        const t = setTimeout(() => {
          if (!opened) { try { sock.close(); } catch{}; setStatus('Signaling: timeout'); reject(new Error('WS timeout')); }
        }, 15000);

        /* https://chatgpt.com/c/68a874e7-225c-832b-b147-60cfea788ffb
        sock.onopen = () => {
          opened = true; clearTimeout(t);
          setStatus('Signaling: connected');
          send({ type: 'join', room, role: 'sender' }); //bm 22/08/2025 15:58 - was: send({ type: 'join', room });
          send({ type: 'need-offer' });
          needOfferTimer = setInterval(() => {
            if (!remoteDescriptionSet) { console.log('[WS OUT] need-offer (retry)'); send({ type: 'need-offer' }); }
            else { clearInterval(needOfferTimer); needOfferTimer = null; }
          }, NEED_OFFER_INTERVAL_MS);
          resolve();
        };
        */
        sock.onopen = () => {
          opened = true; clearTimeout(t);
          setStatus('Signaling: connected');
          send({ type: 'join', room, role: 'sender' });
        
          // Optional: one-time nudge so any already-open receivers offer
          send({ type: 'need-offer' });
        
          resolve();
        };
        //end bm - 22 aug 2025 - 16:48                         
        sock.onmessage = onSignal;
        sock.onerror = (e) => { console.warn('[WS error]', e); };
        sock.onclose  = (e) => { console.warn('[WS closed]', e.code, e.reason); setStatus('Signaling: closed'); };
      });
    }
    const send = (obj) => { try { ws?.readyState === WebSocket.OPEN && ws.send(JSON.stringify(obj)); } catch {} };

    /*bm 22 aug 2025 - 16:45
    function createPC() {
      pc = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
        bundlePolicy: 'max-bundle',
        sdpSemantics: 'unified-plan'
      });

      pc.ondatachannel = (ev) => {
        if (ev.channel?.label === 'pose') {
          const ch = ev.channel;
          console.log('[DC][sender] ondatachannel: pose');
          ch.onopen = () => { console.log('[POSE][sender] DC open (sender side)'); poseDCs.add(ch); announcePoseMode(); };
          ch.onclose = () => { console.log('[POSE][sender] DC close (sender side)'); poseDCs.delete(ch); };
          ch.onerror = (e) => { console.log('[POSE][sender] DC error', e); };
          ch.onmessage = onPoseMessageFromReceiver;
        }
      };

      pc.onicecandidate = (e) => { if (e.candidate) send({ type: 'candidate', candidate: e.candidate }); };
      pc.oniceconnectionstatechange = () => setStatus('ICE: ' + pc.iceConnectionState);

      localStream.getTracks().forEach(track => {
        console.log('[TRACK][sender] addTrack', track.kind);
        pc.addTrack(track, localStream);
      });
    }
    */
    /* revised below: https://chatgpt.com/c/68a874e7-225c-832b-b147-60cfea788ffb
    function getOrCreatePC(peerId) {
      const existing = peers.get(peerId)?.pc;
      if (existing) return existing;
    
      if (!localStream) {
        console.warn('[SENDER] localStream missing; startOrStop() must run first');
      }
    
      const pc = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
        bundlePolicy: 'max-bundle',
        sdpSemantics: 'unified-plan'
      });
    
      // Attach local tracks to *this* connection
      if (localStream) {
        localStream.getTracks().forEach(track => {
          console.log('[TRACK][sender] addTrack', track.kind, '→', peerId);
          pc.addTrack(track, localStream);
        });
      }
    
      // If a receiver opens the "pose" DC, keep your existing logic
      pc.ondatachannel = (ev) => {
        if (ev.channel?.label === 'pose') {
          const ch = ev.channel;
          console.log('[DC][sender] ondatachannel: pose from', peerId);
          ch.onopen  = () => { console.log('[POSE][sender] DC open', peerId); poseDCs.add(ch); announcePoseMode(); };
          ch.onclose = () => { console.log('[POSE][sender] DC close', peerId); poseDCs.delete(ch); };
          ch.onerror = (e) => { console.log('[POSE][sender] DC error', peerId, e); };
          ch.onmessage = onPoseMessageFromReceiver;
        }
      };
    
      pc.onicecandidate = (e) => {
        if (e.candidate && ws?.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ type: 'candidate', to: peerId, candidate: e.candidate }));
        }
      };
    
      pc.onconnectionstatechange = () => {
        const st = pc.connectionState;
        console.log('[SENDER][PC]', peerId, st);
        if (st === 'failed' || st === 'closed') cleanupPeer(peerId, 'pc-state:' + st);
      };
    
      peers.set(peerId, { pc, remoteDescriptionSet: false, candidateQueue: [], lastOfferSdp: null });
      return pc;
    }
    */
    function getOrCreatePC(peerId) {
      let rec = peers.get(peerId);
      if (rec && rec.pc) return rec.pc;
    
      if (!localStream) {
        console.warn('[SENDER] localStream missing; startOrStop() must run first');
      }
    
      const pc = new RTCPeerConnection({
        iceServers: [{ urls: 'stun:stun.l.google.com:19302' }],
        bundlePolicy: 'max-bundle',
        sdpSemantics: 'unified-plan'
      });
    
      // Attach local tracks to *this* connection
      if (localStream) {
        localStream.getTracks().forEach(track => {
          console.log('[TRACK][sender] addTrack', track.kind, '→', peerId);
          pc.addTrack(track, localStream);
        });
      }
    
      // "pose" DC handling (unchanged)
      pc.ondatachannel = (ev) => {
        if (ev.channel?.label === 'pose') {
          const ch = ev.channel;
          console.log('[DC][sender] ondatachannel: pose from', peerId);
          ch.onopen  = () => { console.log('[POSE][sender] DC open', peerId); poseDCs.add(ch); announceAIModes();};
          ch.onclose = () => { console.log('[POSE][sender] DC close', peerId); poseDCs.delete(ch); };
          ch.onerror = (e) => { console.log('[POSE][sender] DC error', peerId, e); };
          ch.onmessage = onPoseMessageFromReceiver;
        }
      };
    
      pc.onicecandidate = (e) => {
        if (e.candidate && ws?.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ type: 'candidate', to: peerId, candidate: e.candidate }));
        }
      };
    
      pc.onconnectionstatechange = () => {
        const st = pc.connectionState;
        console.log('[SENDER][PC]', peerId, st);
        if (st === 'failed' || st === 'closed') cleanupPeer(peerId, 'pc-state:' + st);
      };
    
      // Preserve any existing queued candidates / flags
      if (!rec) {
        rec = { pc, remoteDescriptionSet: false, candidateQueue: [], lastOfferSdp: null };
      } else {
        rec.pc = pc; // keep existing candidateQueue/flags
      }
      peers.set(peerId, rec);
      return pc;
    }
      
    
    function cleanupPeer(peerId, reason = 'cleanup') {
      const rec = peers.get(peerId);
      if (!rec) return;
      try { rec.pc.close(); } catch {}
      peers.delete(peerId);
      console.log('[SENDER] cleaned', peerId, reason);
    }
    //end bm - 22 aug 2025 - 16:46

    /* bm - 22 aug 2025 - 16:51
    async function onSignal(evt) {
      let msg; try { msg = JSON.parse(evt.data); } catch { return; }
      console.log('[WS IN]', msg.type);

      if (msg.type === 'offer') {
        setStatus('Got offer, creating answer…');
        if (!pc) createPC();
        if (pc.signalingState === 'have-local-offer') { try { await pc.setLocalDescription({ type: 'rollback' }); } catch {} }
        if (lastOfferSdp === msg.sdp) { console.log('[DUP] identical offer ignored'); return; }
        lastOfferSdp = msg.sdp;

        //await pc.setRemoteDescription(new RTCSessionDescription(msg));
        await pc.setRemoteDescription(new RTCSessionDescription({ type: msg.type, sdp: msg.sdp })); //bm - 22 aug 2025 - 23:05 - https://chatgpt.com/c/68a8ae44-518c-832e-bf56-0395ef065b37
        
        remoteDescriptionSet = true;

        while (candidateQueue.length) {
          const c = candidateQueue.shift();
          try { await pc.addIceCandidate(c); } catch (err) { console.warn('late ICE add failed', err); }
        }

        const answer = await pc.createAnswer();
        await pc.setLocalDescription(answer);
        send(answer);

      } else if (msg.type === 'candidate' && msg.candidate) {
        const cand = new RTCIceCandidate(msg.candidate);
        if (remoteDescriptionSet && pc) {
          try { await pc.addIceCandidate(cand); } catch (err) { console.warn('ICE add failed', err); }
        } else {
          candidateQueue.push(cand);
        }
      }
    }
    */

    async function onSignal(evt) {
      let msg; try { msg = JSON.parse(evt.data); } catch { return; }
      const t = msg?.type;
    
      if (t === 'peer-left' && msg.id) {
        cleanupPeer(msg.id, 'peer-left');
        return;
      }
    
      if (t === 'bye' && msg.from) {
        cleanupPeer(msg.from, 'bye');
        return;
      }
    
      // When a receiver joins, nudge *that* peer only
      if (t === 'peer-joined' && msg.id && msg.role === 'receiver') {
        ws?.readyState === WebSocket.OPEN &&
          ws.send(JSON.stringify({ type: 'need-offer', to: msg.id }));
        return;
      }
    
      // Optional: if /rooms has existing receivers when we connect
      if (t === 'roster' && Array.isArray(msg.peers)) {
        for (const p of msg.peers) {
          if (p.role === 'receiver') {
            ws?.readyState === WebSocket.OPEN &&
              ws.send(JSON.stringify({ type: 'need-offer', to: p.id }));
          }
        }
        return;
      }
    
      if (t === 'offer' && msg.from) {
        setStatus('Got offer, creating answer…');
    
        const rec = peers.get(msg.from) || {};
        if (rec.lastOfferSdp === msg.sdp) { console.log('[DUP] identical offer ignored from', msg.from); return; }
    
        const pc = getOrCreatePC(msg.from);
    
        // If renegotiating while we have a local offer, roll back
        if (pc.signalingState === 'have-local-offer') {
          try { await pc.setLocalDescription({ type: 'rollback' }); } catch {}
        }
    
        await pc.setRemoteDescription(new RTCSessionDescription(msg));
    
        // flush any queued candidates for this peer
        const state = peers.get(msg.from);
        state.remoteDescriptionSet = true;
        for (const c of state.candidateQueue) {
          try { await pc.addIceCandidate(c); } catch (err) { console.warn('[SENDER] late ICE add failed', msg.from, err); }
        }
        state.candidateQueue.length = 0;
        state.lastOfferSdp = msg.sdp;
    
        const answer = await pc.createAnswer();
        await pc.setLocalDescription(answer);
    
        // IMPORTANT: target the receiver
        const ans = pc.localDescription;
        //ws.send(JSON.stringify({ type: ans.type, sdp: ans.sdp, to: msg.from }));
        const payload = { type: ans.type, sdp: ans.sdp, to: msg.from };
        console.log('[WS OUT] answer →', msg.from);
        ws.send(JSON.stringify(payload));        
        return;
      }
    
      if (t === 'candidate' && msg.from && msg.candidate) {
        const rec = peers.get(msg.from);
        if (!rec) { /* might arrive before offer */ 
          peers.set(msg.from, { pc: null, remoteDescriptionSet: false, candidateQueue: [new RTCIceCandidate(msg.candidate)], lastOfferSdp: null });
          return;
        }
        const pc = rec.pc || getOrCreatePC(msg.from);
        const cand = new RTCIceCandidate(msg.candidate);
        if (rec.remoteDescriptionSet) {
          try { await pc.addIceCandidate(cand); } catch (err) { console.warn('[SENDER] ICE add failed', msg.from, err); }
        } else {
          rec.candidateQueue.push(cand);
        }
        return;
      }
    
      // Ignore noise
      if (t === 'hello' || t === 'keepalive') return;
    }
        //end bm - 22 aug 2025 - 16:51    

    function beginPreviewWindow(minutes) {
      const ms = Math.max(0, Math.round((Number(minutes) || 1) * 60000));
      if (ms === 0) { enterBlackout(); return; }

      document.body.classList.remove('blackout');
      document.body.classList.add('previewing');
      document.body.classList.add('streaming');
      document.body.classList.remove('ui-visible');

      beginViewportSettle();

      previewEnd = Date.now() + ms;
      tickPreviewCountdown();
      previewTicker = setInterval(tickPreviewCountdown, 1000);
      previewTimer  = setTimeout(endPreviewNow, ms);
    }
    function tickPreviewCountdown() {
      const remain = Math.max(0, previewEnd - Date.now());
      const sec = Math.ceil(remain / 1000);
      const mm = String(Math.floor(sec / 60)).padStart(2,'0');
      const ss = String(sec % 60).padStart(2,'0');
      setStatus(`Preview ends in ${mm}:${ss}`);
    }
    function endPreviewNow() {
      if (previewTimer) clearTimeout(previewTimer);
      if (previewTicker) clearInterval(previewTicker);
      previewTimer = previewTicker = null;
      enterBlackout();
    }
    function enterBlackout() {
      document.body.classList.remove('previewing');
      document.body.classList.add('streaming');
      document.body.classList.remove('ui-visible');
      localVideo.style.display = 'none';
      poseCanvas.style.display = 'none';
      setStatus('Streaming...');
      clearTimeout(hideUITimer); hideUITimer = null;
    }

    document.addEventListener('click', (e) => {
      if (document.body.classList.contains('previewing')) { endPreviewNow(); return; }
      if (document.body.classList.contains('streaming') && !document.body.classList.contains('ui-visible')) {
        document.body.classList.add('ui-visible'); setStatus('Streaming...'); scheduleAutoHideUI(); return;
      }
      if (document.body.classList.contains('streaming') && document.body.classList.contains('ui-visible')) {
        const inCard = e.target.closest('.card');
        if (!inCard) { document.body.classList.remove('ui-visible'); setStatus('Streaming...'); clearTimeout(hideUITimer); hideUITimer = null; }
      }
    });
    document.addEventListener('keydown', (e) => {
      if (e.key === 'Escape') {
        if (document.body.classList.contains('previewing')) { endPreviewNow(); }
        else if (document.body.classList.contains('streaming') && document.body.classList.contains('ui-visible')) {
          document.body.classList.remove('ui-visible'); setStatus('Streaming...'); clearTimeout(hideUITimer); hideUITimer = null;
        }
      }
    });
    function scheduleAutoHideUI() {
      clearTimeout(hideUITimer);
      hideUITimer = setTimeout(() => {
        if (document.body.classList.contains('streaming')) {
          document.body.classList.remove('ui-visible');
          setStatus('Streaming...');
        }
      }, UI_AUTOHIDE_MS);
    }

    async function startOrStop() {
      try {
        if (started) { await stopStreaming(); return; }

        startBtn.disabled = true;

        updateMirrorClass();
        const room = currentRoom();
        setStatus('Starting camera…');
        localStream = await getMedia();
        localVideo.srcObject = localStream;
        try { await localVideo.play(); } catch (e) { console.warn('local play blocked', e); }
        beginViewportSettle();

        beginPreviewWindow(Number(previewMinsInput.value) || 1);

        await connectWS(room);
        started = true;
        startBtn.textContent = 'Stop streaming';
        startBtn.disabled = false;

        applyVideoToggle();
        applyAudioToggle();
        //applyPoseUI();
        announceAIModes();

      } catch (err) {
        console.error(err);
        alert(err.message || err);
        setStatus('Idle');
        startBtn.disabled = false;
      }
    }

    /* bm - 22 aug 2025 - 17:06
    async function stopStreaming() {
      try { send({ type: 'bye' }); } catch {}

      if (previewTimer) clearTimeout(previewTimer);
      if (previewTicker) clearInterval(previewTicker);
      if (hideUITimer) clearTimeout(hideUITimer);
      if (needOfferTimer) clearInterval(needOfferTimer);
      previewTimer = previewTicker = hideUITimer = null;

      try { poseLoopRunning = false; } catch {}
      try { poseTask && poseTask.close && poseTask.close(); } catch {}
      poseTask = null;

      try { pc && pc.getSenders().forEach(s => s.track && s.track.stop()); } catch {}
      try { localStream && localStream.getTracks().forEach(t => t.stop()); } catch {}
      try { pc && pc.close(); } catch {}
      try { ws && ws.close(); } catch {}

      poseDCs.clear();

      localStream = null; pc = null; ws = null;
      started = false;

      remoteDescriptionSet = false; //not needed anymore https://chatgpt.com/c/68a874e7-225c-832b-b147-60cfea788ffb
      candidateQueue.length = 0;  //not needed anymore https://chatgpt.com/c/68a874e7-225c-832b-b147-60cfea788ffb
      lastOfferSdp = null;

      document.body.classList.remove('previewing','streaming','ui-visible');
      document.body.classList.add('blackout');

      ui.style.display = '';
      localVideo.style.display = 'none';
      poseCanvas.style.display = 'none';
      ctx.clearRect(0,0,poseCanvas.width, poseCanvas.height);

      setStatus('Stopped');
      startBtn.textContent = 'Start streaming';
    }
    */
    async function stopStreaming() {
      try { send({ type: 'bye' }); } catch {}
    
      // Stop timers
      if (previewTimer)  clearTimeout(previewTimer);
      if (previewTicker) clearInterval(previewTicker);
      if (hideUITimer)   clearTimeout(hideUITimer);
      if (needOfferTimer) clearInterval(needOfferTimer);
      previewTimer = previewTicker = hideUITimer = needOfferTimer = null;
    
      // Stop pose loop/task
      try { poseLoopRunning = false; } catch {}
      try { poseTask && poseTask.close && poseTask.close(); } catch {}
      poseTask = null;

      stopSenderAudioLoop();
      try { audioTask && audioTask.close && audioTask.close(); } catch {}
      audioTask = null;

      // Stop face loop/task
      try { faceLoopRunning = false; } catch {}
      try { faceTask && faceTask.close && faceTask.close(); } catch {}
      faceTask = null;
    
      // ---- Close all RTCPeerConnections ----
      // If using the multi-peer patch: close every per-peer PC
      try {
        if (typeof peers !== 'undefined' && peers && typeof peers.forEach === 'function') {
          for (const [peerId, rec] of peers) {
            try { rec.pc && rec.pc.getSenders()?.forEach(s => s.track && s.track.stop()); } catch {}
            try { rec.pc && rec.pc.close(); } catch {}
          }
          peers.clear();
        }
      } catch {}
    
      // Fallback for the original single-PC implementation
      try {
        if (typeof pc !== 'undefined' && pc) {
          try { pc.getSenders()?.forEach(s => s.track && s.track.stop()); } catch {}
          try { pc.close(); } catch {}
        }
      } catch {}
    
      // Stop local media + WS
      try { localStream && localStream.getTracks().forEach(t => t.stop()); } catch {}
      try { ws && ws.close(); } catch {}
    
      // Datachannels / references
      poseDCs.clear();
    
      // Null refs
      try { localStream = null; } catch {}
      try { ws = null; } catch {}
      try { if (typeof pc !== 'undefined') pc = null; } catch {}
    
      started = false;
    
      // Legacy single-peer flags (harmless if not present)
      try { remoteDescriptionSet = false; } catch {}
      try { candidateQueue && (candidateQueue.length = 0); } catch {}
      try { lastOfferSdp = null; } catch {}
    
      // UI reset
      document.body.classList.remove('previewing','streaming','ui-visible');
      document.body.classList.add('blackout');
    
      ui.style.display = '';
      localVideo.style.display = 'none';
      poseCanvas.style.display = 'none';
      ctx.clearRect(0,0, poseCanvas.width, poseCanvas.height);
    
      setStatus('Stopped');
      startBtn.textContent = 'Start streaming';
    }
    //end - bm 22 aug 2025 - 17:07
    window.addEventListener('beforeunload', stopStreaming);
    startBtn.addEventListener('click', startOrStop);

    function announcePoseMode() {
      const enabled = !!poseOn.checked;
      const where   = poseWhere.value;
      for (const ch of poseDCs) {
        if (ch.readyState === 'open') ch.send(JSON.stringify({ type:'pose-mode', enabled, where }));
      }
      console.log(`[POSE][sender] announce inference-mode: ${where} (enabled: ${enabled} )`);
    }
    async function ensureTasksLoaded() {
      if (PoseLandmarker && FaceLandmarker && FilesetResolver && DrawingUtils) return;
      ({ PoseLandmarker, FaceLandmarker, FilesetResolver, DrawingUtils } = await import(TASKS_URL));
      console.log('[TASKS] Vision tasks loaded');
    }

    async function ensurePoseTask() {
      await ensureTasksLoaded();
      if (poseTask) return poseTask;
      const vision = await FilesetResolver.forVisionTasks(WASM_DIR);
      poseTask = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numPoses: 1
      });
      return poseTask;
    }

    async function ensureFaceTask() {
      await ensureTasksLoaded();
      if (faceTask) return faceTask;
      const vision = await FilesetResolver.forVisionTasks(WASM_DIR);
      faceTask = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numFaces: 1
      });
      return faceTask;
    }

    async function ensureAudioTask() {
      if (audioTask) return audioTask;
      if (!AudioClassifier || !AudioFilesetResolver) {
        ({ AudioClassifier, FilesetResolver: AudioFilesetResolver } = await import(AUDIO_TASKS_URL));
        console.log('[AUDIO][sender] AudioClassifier + FilesetResolver loaded');
      }
      const resolver = await AudioFilesetResolver.forAudioTasks(AUDIO_WASM_DIR);
      audioTask = await AudioClassifier.createFromOptions(resolver, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/audio_classifier/yamnet/float32/1/yamnet.task"
        },
        runningMode: "AUDIO_CLIPS"
      });
      return audioTask;
    }
    
    function sendPoseToReceivers(landmarks) {
      const payload = JSON.stringify({ type:'pose', landmarks, ts: performance.now() });
      for (const ch of poseDCs) if (ch.readyState === 'open') ch.send(payload);
    }
    function drawPoseOnSender(landmarks) {
      if (!landmarks?.length || !poseCanvas.width || !poseCanvas.height) return;
      const dutils = new DrawingUtils(ctx);
      ctx.save();
      ctx.clearRect(0,0, poseCanvas.width, poseCanvas.height);
      for (const lm of landmarks) {
        dutils.drawLandmarks(lm, {
          radius: (data) => DrawingUtils.lerp((data.from && data.from.z) ?? 0, -0.15, 0.1, 5, 1)
        });
        dutils.drawConnectors(lm, PoseLandmarker.POSE_CONNECTIONS);
      }
      ctx.restore();
    }
    async function startSenderPoseLoop() {
      if (!started || !poseOn.checked || poseWhere.value !== 'sender') return;
      const task = await ensurePoseTask();
      poseLoopRunning = true;
      console.log('[POSE][sender] inference START (sender)');
      const loop = async () => {
        if (!poseLoopRunning || !started || !poseOn.checked || poseWhere.value !== 'sender') { console.log('[POSE][sender] inference STOP (sender)'); return; }
        const ts = performance.now();
        const result = task.detectForVideo(localVideo, ts);
        ctx.clearRect(0,0, poseCanvas.width, poseCanvas.height);
        if (result?.landmarks?.length) {
          if (document.body.classList.contains('previewing')) {
            drawPoseOnSender(result.landmarks);
          }
          sendPoseToReceivers(result.landmarks);
        }
        requestAnimationFrame(loop);
      };
      loop();
    }

    
    function stopSenderPoseLoop() {
      poseLoopRunning = false;
      ctx.clearRect(0,0, poseCanvas.width, poseCanvas.height);
    }
    function onPoseMessageFromReceiver(ev) {
      try {
        const msg = JSON.parse(ev.data);
        if (msg.type === 'pose' && document.body.classList.contains('previewing')) {
          drawPoseOnSender(msg.landmarks);
        }
      } catch {}
    }
    function applyPoseUI() {
      //announceAIModes();
      announcePoseMode();
      beginViewportSettle();
      if (!poseOn.checked) { stopSenderPoseLoop(); return; }
      if (started && poseWhere.value === 'sender') startSenderPoseLoop();
      else stopSenderPoseLoop();
    }
    //poseOn.addEventListener('change', () => { console.log(`[POSE][sender] UI → enabled: ${poseOn.checked} | where: ${poseWhere.value}`); announceAIModes(); });
    //poseWhere.addEventListener('change', () => { console.log(`[POSE][sender] UI → enabled: ${poseOn.checked} | where: ${poseWhere.value}`); announceAIModes(); });

    //audio
    async function startSenderAudioLoop() {
      if (!started || !audioAiOn?.checked || audioAiWhere?.value !== 'sender') return;
    
      const task = await ensureAudioTask();
      if (!localStream?.getAudioTracks()?.length) {
        console.warn('[AUDIO][sender] No audio track');
        return;
      }
    
      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const source   = audioCtx.createMediaStreamSource(localStream);
      const processor = audioCtx.createScriptProcessor(1024, 1, 1);
    
      source.connect(processor);
      processor.connect(audioCtx.destination);
    
      const sr = audioCtx.sampleRate;
      const WINDOW_SEC = 0.975;
      const CLIP_SAMPLES = Math.round(sr * WINDOW_SEC);
    
      const chunks = [];
      let totalSamples = 0;
    
      audioLoopRunning = true;
      console.log('[AUDIO][sender] loop START @', sr, 'Hz');
    
      processor.onaudioprocess = async (e) => {
        if (!audioLoopRunning || !started || !audioAiOn.checked || audioAiWhere.value !== 'sender') {
          console.log('[AUDIO][sender] loop STOP');
          try { processor.disconnect(); source.disconnect(); audioCtx.close(); } catch {}
          return;
        }
        const frame = e.inputBuffer.getChannelData(0).slice(0);
        chunks.push(frame);
        totalSamples += frame.length;
    
        while (totalSamples >= CLIP_SAMPLES) {
          const clip = new Float32Array(CLIP_SAMPLES);
          let write = 0;
          while (write < CLIP_SAMPLES && chunks.length) {
            const head = chunks[0];
            const take = Math.min(head.length, CLIP_SAMPLES - write);
            clip.set(head.subarray(0, take), write);
            write += take;
            if (take < head.length) {
              chunks[0] = head.subarray(take);
            } else {
              chunks.shift();
            }
          }
          totalSamples -= CLIP_SAMPLES;
    
          const result = await task.classify({ audioClip: clip, sampleRateHz: sr });
          const classifications = result?.classifications?.[0]?.categories ?? [];
    
          // broadcast raw categories
          const payload = JSON.stringify({ type:'audio', categories: classifications, ts: performance.now() });
          for (const ch of poseDCs) if (ch.readyState === 'open') ch.send(payload);
        }
      };
    }
    
    function stopSenderAudioLoop() {
      audioLoopRunning = false;
    }
    
    function announceAudioMode() {
      const enabled = !!audioAiOn?.checked;
      const where   = audioAiWhere?.value;
      for (const ch of poseDCs) if (ch.readyState === 'open') {
        ch.send(JSON.stringify({ type:'audio-mode', enabled, where }));
      }
    }
    
    function applyAudioUI() {
      if (started && audioAiOn?.checked && audioAiWhere?.value === 'sender') startSenderAudioLoop();
      else stopSenderAudioLoop();
      announceAudioMode();
    }

    // face
    async function startSenderFaceLoop() {
      if (!started || !faceOn?.checked || faceWhere?.value !== 'sender') return;
      const task = await ensureFaceTask();
      faceLoopRunning = true;
      console.log('[FACE][sender] loop START (sender)');
      const loop = () => {
        if (!faceLoopRunning || !started || !faceOn.checked || faceWhere.value !== 'sender') {
          console.log('[FACE][sender] loop STOP (sender)');
          return;
        }
        const ts = performance.now();
        const result = task.detectForVideo(localVideo, ts);
        const payload = JSON.stringify({ type: 'face', landmarks: result?.faceLandmarks ?? null, ts });
        for (const ch of poseDCs) if (ch.readyState === 'open') ch.send(payload);
        requestAnimationFrame(loop);
      };
      loop();
    }
    function stopSenderFaceLoop() { faceLoopRunning = false; }
    function announceFaceMode() {
      const enabled = !!faceOn?.checked;
      const where   = faceWhere?.value;
      for (const ch of poseDCs) if (ch.readyState === 'open') {
        ch.send(JSON.stringify({ type:'face-mode', enabled, where }));
      }
    }
    function applyFaceUI() {
      if (started && faceOn?.checked && faceWhere?.value === 'sender') startSenderFaceLoop();
      else stopSenderFaceLoop();
      announceFaceMode();
    }
    
    announceAIModes(); // ← harmless early initialization
    const qsRoom = new URLSearchParams(location.search).get('room');
    if (qsRoom) roomInput.value = qsRoom;
  </script>
</body>
</html>
