<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>WebRTC Receiver + MediaPipe Pose</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 16px; }
    .grid { display: grid; grid-template-columns: 1fr; gap: 12px; max-width: 980px; margin: 0 auto; }
    video, canvas { width: 100%; max-height: 70vh; background: #000; border-radius: 8px; display: block; }
    textarea { width: 100%; height: 140px; }
    button { padding: 10px 14px; margin: 6px 4px 6px 0; }
    .row { margin: 12px 0; }
    .status { font-weight: 600; }
    .overwrap { position: relative; }
    #overlay { position: absolute; left:0; top:0; pointer-events: none; }
    .small { font-size: 12px; color: #666; }
  </style>
</head>
<body>
  <div class="grid">
    <h1>Receiver (Laptop) + Pose</h1>

    <div class="row">
      <label for="offer">Paste Offer (JSON from iPhone):</label>
      <textarea id="offer" placeholder='{"type":"offer","sdp":"..."}'></textarea>
      <button id="createAnswer">Create Answer</button>
      <button id="copyAnswer" disabled>Copy Answer</button>
      <span class="status" id="pcState">Idle</span>
    </div>

    <textarea id="answer" placeholder="Answer will appear here" readonly></textarea>

    <div class="row">
      <button id="enableAudio" disabled>Enable Audio (if needed)</button>
      <span class="small">Browsers may block autoplay until you click.</span>
    </div>

    <div class="overwrap">
      <video id="remote" playsinline autoplay></video>
      <canvas id="overlay"></canvas>
    </div>

    <div class="row small" id="perf"></div>
  </div>

  <script type="module">
    import {
      FilesetResolver,
      PoseLandmarker,
      DrawingUtils
    } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest";

    const offerTA = document.getElementById('offer');
    const answerTA = document.getElementById('answer');
    const createAnswerBtn = document.getElementById('createAnswer');
    const copyAnswerBtn = document.getElementById('copyAnswer');
    const enableAudioBtn = document.getElementById('enableAudio');
    const pcState = document.getElementById('pcState');
    const video = document.getElementById('remote');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const perf = document.getElementById('perf');

    let pc;
    let landmarker;
    let drawingUtils;
    let lastT = performance.now();
    let fps = 0;
    let inferenceRunning = false;

    function setStatus(s) { pcState.textContent = s; }

    function waitForIceGatheringComplete(pc) {
      if (pc.iceGatheringState === 'complete') return Promise.resolve();
      return new Promise(resolve => {
        function check() {
          if (pc.iceGatheringState === 'complete') {
            pc.removeEventListener('icegatheringstatechange', check);
            resolve();
          }
        }
        pc.addEventListener('icegatheringstatechange', check);
      });
    }

    function resizeOverlayToVideo() {
      const dpr = window.devicePixelRatio || 1;
      const w = video.videoWidth | 0;
      const h = video.videoHeight | 0;
      if (!w || !h) return;
      overlay.style.width = w + "px";
      overlay.style.height = h + "px";
      overlay.width = Math.floor(w * dpr);
      overlay.height = Math.floor(h * dpr);
      ctx.setTransform(dpr, 0, 0, dpr, 0, 0);
    }

    async function initPose() {
      if (landmarker) return; // already initialized

      const fileset = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
      );

      try {
        landmarker = await PoseLandmarker.createFromOptions(fileset, {
          baseOptions: {
            // You can swap to "full" or "heavy"
            modelAssetPath:
              "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/latest/pose_landmarker_lite.task",
            delegate: "GPU"
          },
          runningMode: "video",
          numPoses: 1,
          minPoseDetectionConfidence: 0.4,
          minPosePresenceConfidence: 0.4,
          minTrackingConfidence: 0.4
        });
      } catch (e) {
        // Fallback to CPU if GPU delegate isn't available
        console.warn("GPU delegate failed, retrying with CPU", e);
        landmarker = await PoseLandmarker.createFromOptions(fileset, {
          baseOptions: {
            modelAssetPath:
              "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/latest/pose_landmarker_lite.task",
            delegate: "CPU"
          },
          runningMode: "video",
          numPoses: 1
        });
      }

      drawingUtils = new DrawingUtils(ctx);
    }

    function startInferenceLoop() {
      if (inferenceRunning) return;
      inferenceRunning = true;

      const useVFC = 'requestVideoFrameCallback' in HTMLVideoElement.prototype;

      const step = async (tMs) => {
        if (!landmarker || video.readyState < 2) {
          if (useVFC) {
            video.requestVideoFrameCallback((_now, meta) => step(meta.mediaTime * 1000));
          } else {
            requestAnimationFrame(() => step(performance.now()));
          }
          return;
        }

        const results = await landmarker.detectForVideo(video, tMs);

        // FPS tracking
        const now = performance.now();
        const dt = now - lastT; lastT = now;
        fps = 1000 / dt;
        perf.textContent = `Inference ~ ${fps.toFixed(1)} FPS`;

        // Draw landmarks
        resizeOverlayToVideo();
        ctx.clearRect(0, 0, overlay.width, overlay.height);
        if (results.landmarks) {
          for (const lm of results.landmarks) {
            drawingUtils.drawLandmarks(lm);
          }
        }

        if (useVFC) {
          video.requestVideoFrameCallback((_now, meta) => step(meta.mediaTime * 1000));
        } else {
          requestAnimationFrame(() => step(performance.now()));
        }
      };

      // Kick off once metadata is known
      const kickoff = () => {
        resizeOverlayToVideo();
        if ('requestVideoFrameCallback' in HTMLVideoElement.prototype) {
          video.requestVideoFrameCallback((_now, meta) => step(meta.mediaTime * 1000));
        } else {
          requestAnimationFrame(() => step(performance.now()));
        }
      };

      if (video.readyState >= 2) kickoff();
      else video.onloadedmetadata = kickoff;
    }

    async function createAnswer() {
      const offerVal = offerTA.value.trim();
      if (!offerVal) return alert('Paste the Offer JSON first.');

      pc = new RTCPeerConnection({
        iceServers: [{ urls: ['stun:stun.l.google.com:19302'] }]
      });

      pc.oniceconnectionstatechange = () => setStatus(pc.iceConnectionState);
      pc.onconnectionstatechange = () => setStatus(pc.connectionState);

      pc.ontrack = (e) => {
        // One combined stream with both audio and video
        video.srcObject = e.streams[0];
        enableAudioBtn.disabled = false;
      };

      await pc.setRemoteDescription(JSON.parse(offerVal));
      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);
      await waitForIceGatheringComplete(pc);

      answerTA.value = JSON.stringify(pc.localDescription);
      copyAnswerBtn.disabled = false;

      // Prepare MediaPipe once we know a track will arrive
      await initPose();
      startInferenceLoop();
    }

    createAnswerBtn.onclick = createAnswer;
    copyAnswerBtn.onclick = () => { answerTA.select(); document.execCommand('copy'); };
    enableAudioBtn.onclick = async () => {
      try {
        await video.play(); // unmuted video carries audio
        enableAudioBtn.disabled = true;
      } catch (e) {
        alert('Browser blocked autoplay. Interact with the page and try again.');
      }
    };
  </script>
</body>
</html>
