<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Cat vs Dog Audio Classifier</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/ffmpeg.js/ffmpeg.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/meyda/dist/web/meyda.min.js"></script>
  <style>
    canvas {
      border: 1px solid black;
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <h1>Cat vs Dog Audio Classifier</h1>
  <input type="file" id="audio-upload" accept=".wav" />
  <p id="status">Please upload a .wav file</p>
  <p id="prediction"></p>
  <canvas id="spectrogram" width="800" height="256"></canvas>

  <script type="module">
    import { createFFmpeg, fetchFile } from 'https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.11.6/+esm';

    const MODEL_URL = './tfjs_model_audio/model.json';
    const classNames = ['dog', 'cat'];
    const canvas = document.getElementById('spectrogram');
    const ctx = canvas.getContext('2d');
    const ffmpeg = createFFmpeg({ log: false });

    // Function to resample to 16kHz mono using FFmpeg
    const resampleTo16kMono = async (file) => {
      if (!ffmpeg.isLoaded()) await ffmpeg.load();

      ffmpeg.FS('writeFile', 'input.wav', await fetchFile(file));
      await ffmpeg.run('-i', 'input.wav', '-ar', '16000', '-ac', '1', '-f', 'wav', 'output.wav');

      const data = ffmpeg.FS('readFile', 'output.wav');
      const audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
      const decoded = await audioCtx.decodeAudioData(data.buffer);
      return decoded.getChannelData(0); // Float32Array
    };

    // Spectrogram drawing utility using Meyda
    function drawSpectrogram(waveform, sampleRate = 16000) {
      const bufferSize = 512;
      const hopSize = 256;
      const melBands = 64;

      const frames = Math.floor((waveform.length - bufferSize) / hopSize);
      const spectrogramData = [];

      const analyzer = Meyda.createMeydaAnalyzer({
        audioContext: null,
        bufferSize: bufferSize,
        sampleRate: sampleRate,
        windowingFunction: 'hamming',
        featureExtractors: ['mfcc'],
        numberOfMFCCCoefficients: melBands
      });

      for (let i = 0; i < frames; i++) {
        const start = i * hopSize;
        const frame = waveform.slice(start, start + bufferSize);
        const spectrum = analyzer.extract('mfcc', frame);
        spectrogramData.push(spectrum || new Array(melBands).fill(0));
      }

      const width = canvas.width;
      const height = canvas.height;
      const img = ctx.createImageData(width, height);
      const pixelsPerFrame = Math.floor(width / spectrogramData.length);

      for (let x = 0; x < spectrogramData.length; x++) {
        for (let y = 0; y < melBands; y++) {
          const val = spectrogramData[x][y];
          const intensity = Math.min(255, Math.max(0, (val + 100) * 2)); // Normalize

          const px = x * pixelsPerFrame;
          const py = height - Math.floor((y / melBands) * height);

          for (let dx = 0; dx < pixelsPerFrame; dx++) {
            const index = ((py * width) + px + dx) * 4;
            img.data[index] = intensity;
            img.data[index + 1] = intensity / 2;
            img.data[index + 2] = 0;
            img.data[index + 3] = 255;
          }
        }
      }

      ctx.putImageData(img, 0, 0);
    }

    document.getElementById('audio-upload').addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      document.getElementById('status').innerText = 'Processing audio2...';

      const waveform = await resampleTo16kMono(file);
      drawSpectrogram(waveform);

      const model = await tf.loadGraphModel(MODEL_URL);
      const audioTensor = tf.tensor(waveform).expandDims(0); // [1, num_samples]
      const result = model.predict(audioTensor);
      const probs = await result.data();

      const prediction = classNames[probs.indexOf(Math.max(...probs))];
      document.getElementById('prediction').innerText =
        `Prediction: ${prediction} (dog: ${probs[0].toFixed(3)}, cat: ${probs[1].toFixed(3)})`;
      document.getElementById('status').innerText = 'Done';
    });
  </script>
</body>
</html>
